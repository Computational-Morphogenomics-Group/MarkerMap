{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kuKoVgDwzrgo"
   },
   "source": [
    "# All the Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZgkcUm9Pzn7_",
    "outputId": "b57acdfb-06d1-4c03-e44d-a3977f3c192e"
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "import itertools \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from lassonet import LassoNetClassifier\n",
    "\n",
    "\n",
    "\n",
    "import smashpy as smashpy\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from markermap.utils import RankCorrWrapper\n",
    "from markermap.utils import MarkerMap, ConcreteVAE_NMSL, VAE_Gumbel_GlobalGate, VAE_l1_diag\n",
    "from markermap.utils import (\n",
    "    model_variances,\n",
    "    new_model_metrics, \n",
    "    plot_confusion_matrix,\n",
    "    split_data_into_dataloaders, \n",
    "    train_save_model,\n",
    "    visualize_save_embedding, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger(\"lightning\").setLevel(logging.ERROR)\n",
    "pl_loggers = [ logging.getLogger(name) for name in logging.root.manager.loggerDict if 'lightning' in name ]\n",
    "\n",
    "for logger in pl_loggers:\n",
    "    logger.setLevel(logging.ERROR)\n",
    "    \n",
    "np.warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zli798tc3I1E"
   },
   "source": [
    "# These should be parameters later on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dyZgQa5V3Ird"
   },
   "outputs": [],
   "source": [
    "z_size = 16\n",
    "hidden_layer_size = 64\n",
    "\n",
    "# really good results for vanilla VAE on synthetic data with EPOCHS set to 50, \n",
    "# but when running locally set to 10 for reasonable run times\n",
    "batch_size = 64\n",
    "batch_norm = True\n",
    "\n",
    "\n",
    "global_t = 3.0\n",
    "\n",
    "k_range = [10, 25, 50, 100, 250]\n",
    "num_times = 10\n",
    "k = 50\n",
    "gpus = None\n",
    "tpu_cores = None\n",
    "precision = 32\n",
    "\n",
    "# The smashpy methods set global seeds that mess with sampling. These seeds are used \n",
    "# to stop those methods from using the same global seed over and over.\n",
    "possible_seeds = np.random.randint(low=1, high = 1000000, size = 400)\n",
    "seed_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z3YA3apjf8hc"
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "num_cores = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zNL5KfNXyX_w"
   },
   "source": [
    "# Here goes all the stuff that we change from dataset to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VH7bxl6U3CUC"
   },
   "outputs": [],
   "source": [
    "from os import path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2BQ8JwQoyXhv"
   },
   "outputs": [],
   "source": [
    "dataset_dir = '../data/cite_seq/'\n",
    "model_save_path = '../data/CITE-seq/models/'\n",
    "viz_save_path = '../data/CITE-seq/visualizations/'\n",
    "\n",
    "if not path.exists(model_save_path):\n",
    "  os.makedirs(model_save_path)\n",
    "\n",
    "if not path.exists(model_save_path + 'experiment_data_folds/'):\n",
    "  os.makedirs(model_save_path + 'experiment_data_folds/')\n",
    "  \n",
    "if not path.exists(viz_save_path):\n",
    "  os.makedirs(viz_save_path)\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xv2eoOiMyg3v"
   },
   "source": [
    "# Dataset Specific Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sa6gNnbY-cnt"
   },
   "source": [
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ovIGptmfJpEh"
   },
   "outputs": [],
   "source": [
    "citeseq_adata = sc.read_h5ad(dataset_dir + \"CITEseq.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N5zlHRYVo9W3",
    "outputId": "017d9790-b791-4769-e453-bf2966a08dcf"
   },
   "outputs": [],
   "source": [
    "citeseq_adata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bCMG5lKumTZa"
   },
   "outputs": [],
   "source": [
    "X = citeseq_adata.X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VMroe1buSQOp"
   },
   "outputs": [],
   "source": [
    "citeseq_adata.obs['annotation'] = citeseq_adata.obs['names']\n",
    "labels = citeseq_adata.obs['names'].values\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(labels)\n",
    "y = encoder.transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MmNfRwkAS0JC"
   },
   "outputs": [],
   "source": [
    "input_size = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TDw7r-5hY9oL",
    "outputId": "b574515a-679b-4406-e228-ab88ed11b3a4"
   },
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CpqrOe55ymwy"
   },
   "source": [
    "# Set Up Models\n",
    "\n",
    "Training here will differ than in other notebooks.\n",
    "\n",
    "Training multiple times at k = 50\n",
    "\n",
    "Also training one trial at k's ranging from 10 to 250."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wGsRB_YwTNIs"
   },
   "source": [
    "## All Markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "YxqNOkF-TOtj",
    "outputId": "90d52445-3613-4dc3-ac24-30b00475a8fa"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for tryy in range(1,num_times+1):\n",
    "    _, _, _, train_indices, val_indices, test_indices = split_data_into_dataloaders(X, y, 0.7, 0.1)\n",
    "    all_markers = np.arange(X.shape[1])\n",
    "    X_train = X[np.concatenate([train_indices, val_indices]), :]\n",
    "    y_train = y[np.concatenate([train_indices, val_indices])]\n",
    "    X_test = X[test_indices,:]\n",
    "    y_test = y[test_indices]\n",
    "    results = new_model_metrics(X_train, y_train, X_test, y_test, markers = all_markers)\n",
    "    np.save(model_save_path + 'all_markers_results_{}.npy'.format(tryy), results)\n",
    "    np.save(model_save_path + 'all_markers_{}.npy'.format(tryy), all_markers)\n",
    "    np.save(model_save_path + 'experiment_data_folds/all_markers_indices_{}.npy'.format(tryy), (train_indices, val_indices, test_indices))\n",
    "\n",
    "    visualize_save_embedding(X, y, encoder, 'All Marker Visualization', path = viz_save_path + 'all_markers_{}.pdf'.format(tryy), markers = all_markers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DaU3wodPT7mV"
   },
   "source": [
    "## Train Smash Random Forest\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cJuMQIxtXl-r"
   },
   "outputs": [],
   "source": [
    "# needed for random forest Smash\n",
    "!mkdir Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3xX1y8POT-ob"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for k in k_range:\n",
    "    # The smashpy methods set global seeds that mess with sampling. These seeds are used \n",
    "    # to stop those methods from using the same global seed over and over.\n",
    "    np.random.seed(possible_seeds[seed_index])\n",
    "    seed_index += 1\n",
    "    _, _, _, train_indices, val_indices, test_indices = split_data_into_dataloaders(X, y, 0.7, 0.1)\n",
    "    train_X_y = citeseq_adata[np.concatenate([train_indices, val_indices]), :]\n",
    "    sm = smashpy.smashpy()\n",
    "    clf = sm.ensemble_learning(train_X_y, group_by=\"annotation\", classifier=\"RandomForest\", balance=True, verbose=True)\n",
    "    selectedGenes, selectedGenes_dict = sm.gini_importance(train_X_y, clf, group_by=\"annotation\", verbose=True, restrict_top=(\"global\", k))\n",
    "    # since this selects k per class, need select randomly from each classes\n",
    "    smash_markers = citeseq_adata.var.index.get_indexer(selectedGenes)\n",
    "\n",
    "    X_train = X[np.concatenate([train_indices, val_indices]), :]\n",
    "    y_train = y[np.concatenate([train_indices, val_indices])]\n",
    "    X_test = X[test_indices,:]\n",
    "    y_test = y[test_indices]\n",
    "    results = new_model_metrics(X_train, y_train, X_test, y_test, markers = smash_markers)\n",
    "    np.save(model_save_path + 'smash_rf_results_k_{}.npy'.format(k), results)\n",
    "    np.save(model_save_path + 'smash_rf_markers_k_{}.npy'.format(k), smash_markers)\n",
    "    np.save(model_save_path + 'experiment_data_folds/smash_rf_indices_k_{}.npy'.format(k), (train_indices, val_indices, test_indices))\n",
    "\n",
    "    visualize_save_embedding(X, y, encoder, 'Smash Random Forest Marker Visualization', path = viz_save_path + 'smash_rf_markers_k_{}.png'.format(k), markers = smash_markers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "k = 50\n",
    "for tryy in range(1,num_times+1):\n",
    "    # The smashpy methods set global seeds that mess with sampling. These seeds are used \n",
    "    # to stop those methods from using the same global seed over and over.\n",
    "    np.random.seed(possible_seeds[seed_index])\n",
    "    seed_index += 1\n",
    "    _, _, _, train_indices, val_indices, test_indices = split_data_into_dataloaders(X, y, 0.7, 0.1)\n",
    "    train_X_y = citeseq_adata[np.concatenate([train_indices, val_indices]), :]\n",
    "    sm = smashpy.smashpy()\n",
    "    clf = sm.ensemble_learning(train_X_y, group_by=\"annotation\", classifier=\"RandomForest\", balance=True, verbose=True)\n",
    "    selectedGenes, selectedGenes_dict = sm.gini_importance(train_X_y, clf, group_by=\"annotation\", verbose=True, restrict_top=(\"global\", k))\n",
    "    # since this selects k per class, need select randomly from each classes\n",
    "    smash_markers = citeseq_adata.var.index.get_indexer(selectedGenes)\n",
    "\n",
    "    X_train = X[np.concatenate([train_indices, val_indices]), :]\n",
    "    y_train = y[np.concatenate([train_indices, val_indices])]\n",
    "    X_test = X[test_indices,:]\n",
    "    y_test = y[test_indices]\n",
    "    results = new_model_metrics(X_train, y_train, X_test, y_test, markers = smash_markers)\n",
    "    np.save(model_save_path + 'smash_rf_results_{}.npy'.format(tryy), results)\n",
    "    np.save(model_save_path + 'smash_rf_markers_{}.npy'.format(tryy), smash_markers)\n",
    "    np.save(model_save_path + 'experiment_data_folds/smash_rf_indices_{}.npy'.format(tryy), (train_indices, val_indices, test_indices))\n",
    "\n",
    "    visualize_save_embedding(X, y, encoder, 'Smash Random Forest Marker Visualization', path = viz_save_path + 'smash_rf_markers_{}.png'.format(tryy), markers = smash_markers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "36K-CYMpTuw2"
   },
   "source": [
    "## Train Smash DNN\n",
    "\n",
    "the data is treated a bit differently than our other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dihae7ssynzJ"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for k in k_range:\n",
    "    # The smashpy methods set global seeds that mess with sampling. These seeds are used \n",
    "    # to stop those methods from using the same global seed over and over.\n",
    "    np.random.seed(possible_seeds[seed_index])\n",
    "    seed_index += 1\n",
    "    _, _, _, train_indices, val_indices, test_indices = split_data_into_dataloaders(X, y, 0.7, 0.1)\n",
    "    train_X_y = citeseq_adata[np.concatenate([train_indices, val_indices]), :]\n",
    "    sm = smashpy.smashpy()\n",
    "    sm.DNN(citeseq_adata, group_by=\"annotation\", model=None, balance=True, verbose=True, save=False)\n",
    "    selectedGenes, selectedGenes_dict = sm.run_shap(citeseq_adata, group_by=\"annotation\", model=None, verbose=True, pct=0.1, restrict_top=(\"global\", k))\n",
    "    # since this selects k per class, need select randomly from each classes\n",
    "    smash_markers = citeseq_adata.var.index.get_indexer(selectedGenes)\n",
    "\n",
    "    X_train = X[np.concatenate([train_indices, val_indices]), :]\n",
    "    y_train = y[np.concatenate([train_indices, val_indices])]\n",
    "    X_test = X[test_indices,:]\n",
    "    y_test = y[test_indices]\n",
    "    results = new_model_metrics(X_train, y_train, X_test, y_test, markers = smash_markers)\n",
    "    np.save(model_save_path + 'smash_results_k_{}.npy'.format(k), results)\n",
    "    np.save(model_save_path + 'smash_markers_k_{}.npy'.format(k), smash_markers)\n",
    "    np.save(model_save_path + 'experiment_data_folds/smash_indices_k_{}.npy'.format(k), (train_indices, val_indices, test_indices))\n",
    "\n",
    "    visualize_save_embedding(X, y, encoder, 'Smash Marker Visualization', path = viz_save_path + 'smash_markers_k_{}.png'.format(k), markers = smash_markers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "k = 50\n",
    "for tryy in range(1,num_times+1):\n",
    "    # The smashpy methods set global seeds that mess with sampling. These seeds are used \n",
    "    # to stop those methods from using the same global seed over and over.\n",
    "    np.random.seed(possible_seeds[seed_index])\n",
    "    seed_index += 1\n",
    "    _, _, _, train_indices, val_indices, test_indices = split_data_into_dataloaders(X, y, 0.7, 0.1)\n",
    "    train_X_y = citeseq_adata[np.concatenate([train_indices, val_indices]), :]\n",
    "    sm = smashpy.smashpy()\n",
    "    sm.DNN(train_X_y, group_by=\"annotation\", model=None, balance=True, verbose=True, save=False)\n",
    "    selectedGenes, selectedGenes_dict = sm.run_shap(train_X_y, group_by=\"annotation\", model=None, verbose=True, pct=0.1, restrict_top=(\"global\", k))\n",
    "    # since this selects k per class, need select randomly from each classes\n",
    "    smash_markers = citeseq_adata.var.index.get_indexer(selectedGenes)\n",
    "\n",
    "    X_train = X[np.concatenate([train_indices, val_indices]), :]\n",
    "    y_train = y[np.concatenate([train_indices, val_indices])]\n",
    "    X_test = X[test_indices,:]\n",
    "    y_test = y[test_indices]\n",
    "    results = new_model_metrics(X_train, y_train, X_test, y_test, markers = smash_markers)\n",
    "    np.save(model_save_path + 'smash_results_{}.npy'.format(tryy), results)\n",
    "    np.save(model_save_path + 'smash_markers_{}.npy'.format(tryy), smash_markers)\n",
    "    np.save(model_save_path + 'experiment_data_folds/smash_indices_{}.npy'.format(tryy), (train_indices, val_indices, test_indices))\n",
    "\n",
    "    visualize_save_embedding(X, y, encoder, 'Smash Marker Visualization', path = viz_save_path + 'smash_markers_{}.png'.format(tryy), markers = smash_markers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The smashpy methods set global seeds that mess with sampling. These seeds are used \n",
    "# to stop those methods from using the same global seed over and over.\n",
    "np.random.seed(possible_seeds[seed_index])\n",
    "seed_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L9kicuw3OKgq"
   },
   "source": [
    "## Train RankCorr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i8eSURuyglO1"
   },
   "outputs": [],
   "source": [
    "lamb_range = [0.5, 1.5, 3, 7, 21.9]\n",
    "lamb_i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MfzfhotGKNxo"
   },
   "outputs": [],
   "source": [
    "for k in k_range:\n",
    "    _, _, _, train_indices, val_indices, test_indices = split_data_into_dataloaders(X, y, 0.7, 0.1)\n",
    "    X_train = X[np.concatenate([train_indices, val_indices]), :]\n",
    "    y_train = y[np.concatenate([train_indices, val_indices])]\n",
    "    X_test = X[test_indices,:]\n",
    "    y_test = y[test_indices]\n",
    "\n",
    "    data = RankCorrWrapper(X_train, y_train)\n",
    "    lamb = lamb_range[lamb_i]\n",
    "    lamb_i = lamb_i + 1\n",
    "\n",
    "    rankcorr_markers = data.CSrankMarkers(lamb=lamb, writeOut=False, keepZeros=False, onlyNonZero=False)\n",
    "    if len(rankcorr_markers) < k:\n",
    "        print(lamb)\n",
    "        print(len(rankcorr_markers))\n",
    "        print(k)\n",
    "        raise Exception(\"Increase lamb for rank corr procedure\")\n",
    "    if len(rankcorr_markers) > k:\n",
    "        #print(\"Excess Length of markers\")\n",
    "        #print(len(rankcorr_markers))\n",
    "        rankcorr_markers = rankcorr_markers[:k]\n",
    "    \n",
    "\n",
    "    results = new_model_metrics(X_train, y_train, X_test, y_test, markers = rankcorr_markers)\n",
    "    np.save(model_save_path + 'rankcorr_results_k_{}.npy'.format(k), results)\n",
    "    np.save(model_save_path + 'rankcorr_markers_k_{}.npy'.format(k), rankcorr_markers)\n",
    "    np.save(model_save_path + 'experiment_data_folds/rankcorr_indices_k_{}.npy'.format(k), (train_indices, val_indices, test_indices))\n",
    "\n",
    "    visualize_save_embedding(X, y, encoder, 'RankCorr Marker Visualization', path = viz_save_path + 'rankcorr_markers_k_{}.png'.format(k), markers = rankcorr_markers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 50\n",
    "for tryy in range(1,num_times+1):\n",
    "    _, _, _, train_indices, val_indices, test_indices = split_data_into_dataloaders(X, y, 0.7, 0.1)\n",
    "    X_train = X[np.concatenate([train_indices, val_indices]), :]\n",
    "    y_train = y[np.concatenate([train_indices, val_indices])]\n",
    "    X_test = X[test_indices,:]\n",
    "    y_test = y[test_indices]\n",
    "\n",
    "    data = RankCorrWrapper(X_train, y_train)\n",
    "    lamb = 3.2# this can be whatever\n",
    "\n",
    "    rankcorr_markers = data.CSrankMarkers(lamb=lamb, writeOut=False, keepZeros=False, onlyNonZero=False)\n",
    "    if len(rankcorr_markers) < k:\n",
    "        raise Exception(\"Increase lamb for rank corr procedure\")\n",
    "    if len(rankcorr_markers) > k:\n",
    "        #print(\"Excess Length of markers\")\n",
    "        #print(len(rankcorr_markers))\n",
    "        rankcorr_markers = rankcorr_markers[:k]\n",
    "    \n",
    "\n",
    "    results = new_model_metrics(X_train, y_train, X_test, y_test, markers = rankcorr_markers)\n",
    "    np.save(model_save_path + 'rankcorr_results_{}.npy'.format(tryy), results)\n",
    "    np.save(model_save_path + 'rankcorr_markers_{}.npy'.format(tryy), rankcorr_markers)\n",
    "    np.save(model_save_path + 'experiment_data_folds/rankcorr_indices_{}.npy'.format(tryy), (train_indices, val_indices, test_indices))\n",
    "\n",
    "    visualize_save_embedding(X, y, encoder, 'RankCorr Marker Visualization', path = viz_save_path + 'rankcorr_markers_{}.png'.format(tryy), markers = rankcorr_markers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4UT0YG-m9CxL"
   },
   "source": [
    "## Train L1 VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wcTlqJiJ9CgS"
   },
   "outputs": [],
   "source": [
    "feature_std = torch.tensor(X).std(dim = 0)\n",
    "for k in k_range:\n",
    "    train_dataloader, val_dataloader, _, train_indices, val_indices, test_indices = split_data_into_dataloaders(X, y, 0.7, 0.1, num_workers = num_cores, batch_size = batch_size)\n",
    "    X_train = X[np.concatenate([train_indices, val_indices]), :]\n",
    "    y_train = y[np.concatenate([train_indices, val_indices])]\n",
    "    X_test = X[test_indices,:]\n",
    "    y_test = y[test_indices]\n",
    "\n",
    "    model = VAE_l1_diag(input_size, hidden_layer_size, z_size, batch_norm = batch_norm)\n",
    "    tmp_path = model_save_path + 'l1_vae_k_{}.ckpt'.format(k)\n",
    "    # DO NOT USE IN OTHER WORKLOADS\n",
    "    train_save_model(model, train_dataloader, val_dataloader, tmp_path, gpus=gpus, tpu_cores = tpu_cores, min_epochs = 25, \n",
    "                     max_epochs = 100, auto_lr = True, early_stopping_patience = 4, precision = precision)\n",
    "    l1_markers = model.markers(feature_std = feature_std.to(model.device), k = k).clone().cpu().detach().numpy()\n",
    "    \n",
    "\n",
    "    results = new_model_metrics(X_train, y_train, X_test, y_test, markers = l1_markers)\n",
    "    np.save(model_save_path + 'l1_vae_results_k_{}.npy'.format(k), results)\n",
    "    np.save(model_save_path + 'l1_vae_markers_k_{}.npy'.format(k), l1_markers)\n",
    "    np.save(model_save_path + 'experiment_data_folds/l1_vae_indices_k_{}.npy'.format(k), (train_indices, val_indices, test_indices))\n",
    "\n",
    "    visualize_save_embedding(X, y, encoder, 'L1 VAE Marker Visualization', path = viz_save_path + 'l1_vae_markers_k_{}.png'.format(k), markers = l1_markers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_std = torch.tensor(X).std(dim = 0)\n",
    "k = 50\n",
    "for tryy in range(1,num_times+1):\n",
    "    train_dataloader, val_dataloader, _, train_indices, val_indices, test_indices = split_data_into_dataloaders(X, y, 0.7, 0.1, num_workers = num_cores, batch_size = batch_size)\n",
    "    X_train = X[np.concatenate([train_indices, val_indices]), :]\n",
    "    y_train = y[np.concatenate([train_indices, val_indices])]\n",
    "    X_test = X[test_indices,:]\n",
    "    y_test = y[test_indices]\n",
    "\n",
    "    model = VAE_l1_diag(input_size, hidden_layer_size, z_size, batch_norm = batch_norm)\n",
    "    tmp_path = model_save_path + 'l1_vae_{}.ckpt'.format(tryy)\n",
    "    # DO NOT USE IN OTHER WORKLOADS\n",
    "    train_save_model(model, train_dataloader, val_dataloader, tmp_path, gpus=gpus, tpu_cores = tpu_cores, min_epochs = 25, \n",
    "                     max_epochs = 100, auto_lr = True, early_stopping_patience = 4, precision = precision)\n",
    "    l1_markers = model.markers(feature_std = feature_std.to(model.device), k = k).clone().cpu().detach().numpy()\n",
    "    \n",
    "\n",
    "    results = new_model_metrics(X_train, y_train, X_test, y_test, markers = l1_markers)\n",
    "    np.save(model_save_path + 'l1_vae_results_{}.npy'.format(tryy), results)\n",
    "    np.save(model_save_path + 'l1_vae_markers_{}.npy'.format(tryy), l1_markers)\n",
    "    np.save(model_save_path + 'experiment_data_folds/l1_vae_indices_{}.npy'.format(tryy), (train_indices, val_indices, test_indices))\n",
    "\n",
    "    visualize_save_embedding(X, y, encoder, 'L1 VAE Marker Visualization', path = viz_save_path + 'l1_vae_markers_{}.png'.format(tryy), markers = l1_markers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NTLLf99HA1o6"
   },
   "source": [
    "## Train Global Gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G3gYOblwA0r5"
   },
   "outputs": [],
   "source": [
    "for k in k_range:\n",
    "    train_dataloader, val_dataloader, _, train_indices, val_indices, test_indices = split_data_into_dataloaders(X, y, 0.7, 0.1, num_workers=num_cores, batch_size = batch_size)\n",
    "    X_train = X[np.concatenate([train_indices, val_indices]), :]\n",
    "    y_train = y[np.concatenate([train_indices, val_indices])]\n",
    "    X_test = X[test_indices,:]\n",
    "    y_test = y[test_indices]\n",
    "\n",
    "    model = VAE_Gumbel_GlobalGate(input_size, hidden_layer_size, z_size, k = k, t = global_t, bias = True, temperature_decay=0.95, batch_norm = batch_norm)\n",
    "    tmp_path = model_save_path + 'globalgate_vae_k_{}.ckpt'.format(k)\n",
    "    # DO NOT USE IN OTHER WORKLOADS\n",
    "    train_save_model(model, train_dataloader, val_dataloader, tmp_path, gpus = gpus, tpu_cores = tpu_cores, \n",
    "                     min_epochs = 25, max_epochs = 100, auto_lr = True, max_lr = 0.00001, early_stopping_patience =  10, \n",
    "                     lr_explore_mode = 'linear', num_lr_rates = 500, precision = precision)\n",
    "    globalgate_markers = model.markers().clone().cpu().detach().numpy()\n",
    "    \n",
    " \n",
    "    results = new_model_metrics(X_train, y_train, X_test, y_test, markers = globalgate_markers)\n",
    "    np.save(model_save_path + 'globalgate_vae_results_k_{}.npy'.format(k), results)\n",
    "    np.save(model_save_path + 'globalgate_vae_markers_k_{}.npy'.format(k), globalgate_markers)\n",
    "    np.save(model_save_path + 'experiment_data_folds/globalgate_vae_indices_k_{}.npy'.format(k), (train_indices, val_indices, test_indices))\n",
    "\n",
    "    visualize_save_embedding(X, y, encoder, 'Global Gate VAE Marker Visualization', path = viz_save_path + 'globalgate_vae_markers_k_{}.png'.format(k), markers = globalgate_markers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 50\n",
    "for tryy in range(1,num_times+1):\n",
    "    train_dataloader, val_dataloader, _, train_indices, val_indices, test_indices = split_data_into_dataloaders(X, y, 0.7, 0.1, num_workers=num_cores, batch_size = batch_size)\n",
    "    X_train = X[np.concatenate([train_indices, val_indices]), :]\n",
    "    y_train = y[np.concatenate([train_indices, val_indices])]\n",
    "    X_test = X[test_indices,:]\n",
    "    y_test = y[test_indices]\n",
    "\n",
    "    model = VAE_Gumbel_GlobalGate(input_size, hidden_layer_size, z_size, k = k, t = global_t, bias = True, temperature_decay=0.95, batch_norm = batch_norm)\n",
    "    tmp_path = model_save_path + 'globalgate_vae_{}.ckpt'.format(tryy)\n",
    "    # DO NOT USE IN OTHER WORKLOADS\n",
    "    train_save_model(model, train_dataloader, val_dataloader, tmp_path, gpus = gpus, tpu_cores = tpu_cores, \n",
    "                     min_epochs = 25, max_epochs = 100, auto_lr = True, max_lr = 0.00001, early_stopping_patience =  10, \n",
    "                     lr_explore_mode = 'linear', num_lr_rates = 500, precision = precision)\n",
    "    globalgate_markers = model.markers().clone().cpu().detach().numpy()\n",
    "    \n",
    " \n",
    "    results = new_model_metrics(X_train, y_train, X_test, y_test, markers = globalgate_markers)\n",
    "    np.save(model_save_path + 'globalgate_vae_results_{}.npy'.format(tryy), results)\n",
    "    np.save(model_save_path + 'globalgate_vae_markers_{}.npy'.format(tryy), globalgate_markers)\n",
    "    np.save(model_save_path + 'experiment_data_folds/globalgate_vae_indices_{}.npy'.format(tryy), (train_indices, val_indices, test_indices))\n",
    "\n",
    "    visualize_save_embedding(X, y, encoder, 'Global Gate VAE Marker Visualization', path = viz_save_path + 'globalgate_vae_markers_{}.png'.format(tryy), markers = globalgate_markers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Kh0fu77RlWp"
   },
   "source": [
    "## Train MarkerMap Unsupervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I9BoR6M-Rnfm"
   },
   "outputs": [],
   "source": [
    "for k in k_range:\n",
    "    train_dataloader, val_dataloader, _, train_indices, val_indices, test_indices = split_data_into_dataloaders(X, y, 0.7, 0.1, num_workers = num_cores, batch_size = batch_size)\n",
    "    X_train = X[np.concatenate([train_indices, val_indices]), :]\n",
    "    y_train = y[np.concatenate([train_indices, val_indices])]\n",
    "    X_test = X[test_indices,:]\n",
    "    y_test = y[test_indices]\n",
    "    model = MarkerMap(input_size, hidden_layer_size, z_size, k = k, t = global_t, bias = True, temperature_decay=0.95, alpha = 0.95, batch_norm = batch_norm, loss_tradeoff = 1.0, num_classes = None)\n",
    "    tmp_path = model_save_path + 'marker_map_unsupervised_k_{}.ckpt'.format(k)\n",
    "    # DO NOT USE IN OTHER WORKLOADS\n",
    "    train_save_model(model, train_dataloader, val_dataloader, tmp_path, gpus=1, min_epochs = 25, max_epochs = 100, auto_lr = True, max_lr = 0.0001, early_stopping_patience = 4, \n",
    "                     lr_explore_mode = 'linear', num_lr_rates = 500, precision = precision)\n",
    "    marker_map_unsupervised_markers = model.markers().clone().cpu().detach().numpy()\n",
    "    \n",
    "\n",
    "    results = new_model_metrics(X_train, y_train, X_test, y_test, markers = marker_map_unsupervised_markers)\n",
    "    np.save(model_save_path + 'marker_map_unsupervised_results_k_{}.npy'.format(k), results)\n",
    "    np.save(model_save_path + 'marker_map_unsupervised_markers_k_{}.npy'.format(k), marker_map_unsupervised_markers)\n",
    "    np.save(model_save_path + 'experiment_data_folds/marker_map_unsupervised_indices_k_{}.npy'.format(k), (train_indices, val_indices, test_indices))\n",
    "\n",
    "    visualize_save_embedding(X, y, encoder, 'MarkerMap Unsupervised Marker Visualization', path = viz_save_path + 'marker_map_unsupervised_markers_k_{}.png'.format(k), markers = marker_map_unsupervised_markers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 50\n",
    "for tryy in range(1,num_times+1):\n",
    "    train_dataloader, val_dataloader, _, train_indices, val_indices, test_indices = split_data_into_dataloaders(X, y, 0.7, 0.1, num_workers = num_cores, batch_size = batch_size)\n",
    "    X_train = X[np.concatenate([train_indices, val_indices]), :]\n",
    "    y_train = y[np.concatenate([train_indices, val_indices])]\n",
    "    X_test = X[test_indices,:]\n",
    "    y_test = y[test_indices]\n",
    "    model = MarkerMap(input_size, hidden_layer_size, z_size, k = k, t = global_t, bias = True, temperature_decay=0.95, alpha = 0.95, batch_norm = batch_norm, loss_tradeoff = 1.0, num_classes = None)\n",
    "    tmp_path = model_save_path + 'marker_map_unsupervised_{}.ckpt'.format(tryy)\n",
    "    # DO NOT USE IN OTHER WORKLOADS\n",
    "    train_save_model(model, train_dataloader, val_dataloader, tmp_path, gpus=1, min_epochs = 25, max_epochs = 100, auto_lr = True, max_lr = 0.0001, early_stopping_patience = 4, \n",
    "                     lr_explore_mode = 'linear', num_lr_rates = 500, precision = precision)\n",
    "    unsupervised_markers = model.markers().clone().cpu().detach().numpy()\n",
    "    \n",
    "\n",
    "    results = new_model_metrics(X_train, y_train, X_test, y_test, markers = unsupervised_markers)\n",
    "    np.save(model_save_path + 'marker_map_unsupervised_results_{}.npy'.format(tryy), results)\n",
    "    np.save(model_save_path + 'marker_map_unsupervised_markers_{}.npy'.format(tryy), unsupervised_markers)\n",
    "    np.save(model_save_path + 'experiment_data_folds/marker_map_unsupervised_indices_{}.npy'.format(tryy), (train_indices, val_indices, test_indices))\n",
    "\n",
    "    visualize_save_embedding(X, y, encoder, 'Marker Map Unsupervised Marker Visualization', path = viz_save_path + 'marker_map_unsupervised_markers_{}.png'.format(tryy), markers = unsupervised_markers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "06HHTH8FUSOs"
   },
   "source": [
    "## MarkerMap Supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rFKATvJ0UVoy"
   },
   "outputs": [],
   "source": [
    "for k in k_range:\n",
    "    train_dataloader, val_dataloader, _, train_indices, val_indices, test_indices = split_data_into_dataloaders(X, y, 0.7, 0.1, num_workers = num_cores, batch_size = batch_size)\n",
    "    X_train = X[np.concatenate([train_indices, val_indices]), :]\n",
    "    y_train = y[np.concatenate([train_indices, val_indices])]\n",
    "    X_test = X[test_indices,:]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    model = MarkerMap(input_size, hidden_layer_size, z_size, num_classes = len(encoder.classes_), \n",
    "                             k = k, t = global_t, bias = True, temperature_decay=0.95, alpha = 0.95, batch_norm = batch_norm, loss_tradeoff = 0)\n",
    "    tmp_path = model_save_path + 'marker_map_supervised_k_{}.ckpt'.format(k)\n",
    "    # DO NOT USE IN OTHER WORKLOADS\n",
    "    train_save_model(model, train_dataloader, val_dataloader, tmp_path, gpus=gpus, tpu_cores = tpu_cores, \n",
    "                     min_epochs = 25, max_epochs = 100, auto_lr = True, early_stopping_patience = 3, precision = precision, lr_explore_mode = 'linear', num_lr_rates=500)\n",
    "    markers = model.markers().clone().cpu().detach().numpy()\n",
    "    \n",
    "\n",
    "    results = new_model_metrics(X_train, y_train, X_test, y_test, markers = markers)\n",
    "    np.save(model_save_path + 'marker_map_supervised_results_k_{}.npy'.format(k), results)\n",
    "    np.save(model_save_path + 'marker_map_supervised_markers_k_{}.npy'.format(k), markers)\n",
    "    np.save(model_save_path + 'experiment_data_folds/marker_map_supervised_indices_k_{}.npy'.format(k), (train_indices, val_indices, test_indices))\n",
    "\n",
    "    visualize_save_embedding(X, y, encoder, 'MarkerMap Supervised Marker Visualization', path = viz_save_path + 'marker_map_supervised_markers_k_{}.png'.format(k), markers = markers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 50\n",
    "for tryy in range(1,num_times+1):\n",
    "    train_dataloader, val_dataloader, _, train_indices, val_indices, test_indices = split_data_into_dataloaders(X, y, 0.7, 0.1, num_workers = num_cores, batch_size = batch_size)\n",
    "    X_train = X[np.concatenate([train_indices, val_indices]), :]\n",
    "    y_train = y[np.concatenate([train_indices, val_indices])]\n",
    "    X_test = X[test_indices,:]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    model = MarkerMap(input_size, hidden_layer_size, z_size, num_classes = len(encoder.classes_), \n",
    "                             k = k, t = global_t, bias = True, temperature_decay=0.95, alpha = 0.95, batch_norm = batch_norm, loss_tradeoff = 0)\n",
    "    tmp_path = model_save_path + 'marker_map_supervised_{}.ckpt'.format(tryy)\n",
    "    # DO NOT USE IN OTHER WORKLOADS\n",
    "    train_save_model(model, train_dataloader, val_dataloader, tmp_path, gpus=gpus, tpu_cores = tpu_cores, \n",
    "                     min_epochs = 25, max_epochs = 100, auto_lr = True, early_stopping_patience = 3, precision = precision, lr_explore_mode = 'linear', num_lr_rates=500)\n",
    "    markers = model.markers().clone().cpu().detach().numpy()\n",
    "    \n",
    "\n",
    "    results = new_model_metrics(X_train, y_train, X_test, y_test, markers = markers)\n",
    "    np.save(model_save_path + 'marker_map_supervised_results_{}.npy'.format(tryy), results)\n",
    "    np.save(model_save_path + 'marker_map_supervised_markers_{}.npy'.format(tryy), markers)\n",
    "    np.save(model_save_path + 'experiment_data_folds/marker_map_supervised_indices_{}.npy'.format(tryy), (train_indices, val_indices, test_indices))\n",
    "\n",
    "    visualize_save_embedding(X, y, encoder, 'MarkerMap Supervised Marker Visualization', path = viz_save_path + 'marker_map_supervised_markers_{}.png'.format(tryy), markers = markers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iCQxCjO92hYO"
   },
   "source": [
    "## Train MarkerMap Mixed Supervision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S6rktn672jf8"
   },
   "outputs": [],
   "source": [
    "for tryy in k_range:\n",
    "    train_dataloader, val_dataloader, _, train_indices, val_indices, test_indices = split_data_into_dataloaders(X, y, 0.7, 0.1, num_workers = num_cores, batch_size = batch_size)\n",
    "    X_train = X[np.concatenate([train_indices, val_indices]), :]\n",
    "    y_train = y[np.concatenate([train_indices, val_indices])]\n",
    "    X_test = X[test_indices,:]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    model = MarkerMap(input_size, hidden_layer_size, z_size, num_classes = len(encoder.classes_), \n",
    "                             k = k, t = global_t, bias = True, temperature_decay=0.95, alpha = 0.95, batch_norm = batch_norm, loss_tradeoff = 0.5)\n",
    "    tmp_path = model_save_path + 'marker_map_mixed_k_{}.ckpt'.format(tryy)\n",
    "    # DO NOT USE IN OTHER WORKLOADS\n",
    "    train_save_model(model, train_dataloader, val_dataloader, tmp_path, gpus=gpus, tpu_cores = tpu_cores, \n",
    "                     min_epochs = 25, max_epochs = 100, auto_lr = True, early_stopping_patience = 3, precision = precision, lr_explore_mode = 'linear', num_lr_rates=500)\n",
    "    markers = model.markers().clone().cpu().detach().numpy()\n",
    "    \n",
    "\n",
    "    results = new_model_metrics(X_train, y_train, X_test, y_test, markers = markers)\n",
    "    np.save(model_save_path + 'marker_map_mixed_results_k_{}.npy'.format(tryy), results)\n",
    "    np.save(model_save_path + 'marker_map_mixed_markers_k_{}.npy'.format(tryy), markers)\n",
    "    np.save(model_save_path + 'experiment_data_folds/marker_map_mixed_indices_k_{}.npy'.format(tryy), (train_indices, val_indices, test_indices))\n",
    "\n",
    "    visualize_save_embedding(X, y, encoder, 'MarkerMap Mixed Supervision Marker Visualization', path = viz_save_path + 'marker_map_mixed_markers_k_{}.png'.format(tryy), markers = markers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 50\n",
    "for tryy in range(1,num_times+1):\n",
    "    train_dataloader, val_dataloader, _, train_indices, val_indices, test_indices = split_data_into_dataloaders(X, y, 0.7, 0.1, num_workers = num_cores, batch_size = batch_size)\n",
    "    X_train = X[np.concatenate([train_indices, val_indices]), :]\n",
    "    y_train = y[np.concatenate([train_indices, val_indices])]\n",
    "    X_test = X[test_indices,:]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    model = MarkerMap(input_size, hidden_layer_size, z_size, num_classes = len(encoder.classes_), \n",
    "                             k = k, t = global_t, bias = True, temperature_decay=0.95, alpha = 0.95, batch_norm = batch_norm, loss_tradeoff = 0.5)\n",
    "    tmp_path = model_save_path + 'marker_map_mixed_{}.ckpt'.format(tryy)\n",
    "    # DO NOT USE IN OTHER WORKLOADS\n",
    "    train_save_model(model, train_dataloader, val_dataloader, tmp_path, gpus=gpus, tpu_cores = tpu_cores, \n",
    "                     min_epochs = 25, max_epochs = 100, auto_lr = True, early_stopping_patience = 3, precision = precision, lr_explore_mode = 'linear', num_lr_rates=500)\n",
    "    markers = model.markers().clone().cpu().detach().numpy()\n",
    "    \n",
    "\n",
    "    results = new_model_metrics(X_train, y_train, X_test, y_test, markers = markers)\n",
    "    np.save(model_save_path + 'marker_map_mixed_results_{}.npy'.format(tryy), results)\n",
    "    np.save(model_save_path + 'marker_map_mixed_markers_{}.npy'.format(tryy), markers)\n",
    "    np.save(model_save_path + 'experiment_data_folds/marker_map_mixed_indices_{}.npy'.format(tryy), (train_indices, val_indices, test_indices))\n",
    "\n",
    "    visualize_save_embedding(X, y, encoder, 'MarkerMap Mixed Supervision Marker Visualization', path = viz_save_path + 'marker_map_mixed_markers_{}.png'.format(tryy), markers = markers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z_uAjoDSde-v"
   },
   "source": [
    "## Concrete VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "eqbs1Ni8ypMY"
   },
   "outputs": [],
   "source": [
    "for k in k_range:\n",
    "    train_dataloader, val_dataloader, _, train_indices, val_indices, test_indices = split_data_into_dataloaders(X, y, 0.7, 0.1, num_workers = num_cores, batch_size = batch_size)\n",
    "    X_train = X[np.concatenate([train_indices, val_indices]), :]\n",
    "    y_train = y[np.concatenate([train_indices, val_indices])]\n",
    "    X_test = X[test_indices,:]\n",
    "    y_test = y[test_indices]\n",
    "\n",
    "    model = ConcreteVAE_NMSL(input_size, hidden_layer_size, z_size, k = k, t = global_t, bias = True, temperature_decay = 0.9, batch_norm = batch_norm)\n",
    "    tmp_path = model_save_path + 'concrete_vae_k_{}.ckpt'.format(k)\n",
    "    train_save_model(model, train_dataloader, val_dataloader, tmp_path, gpus=1, min_epochs = 25, max_epochs = 100, auto_lr = True, max_lr = 0.0001, early_stopping_patience = 3, \n",
    "                     lr_explore_mode = 'linear', num_lr_rates = 500, precision = 16)\n",
    "    concrete_vae_markers = model.markers().clone().cpu().detach().numpy()\n",
    "    \n",
    "\n",
    "    results = new_model_metrics(X_train, y_train, X_test, y_test, markers = concrete_vae_markers)\n",
    "    np.save(model_save_path + 'concrete_vae_results_k_{}.npy'.format(k), results)\n",
    "    np.save(model_save_path + 'concrete_vae_markers_k_{}.npy'.format(k), concrete_vae_markers)\n",
    "    np.save(model_save_path + 'experiment_data_folds/concrete_vae_indices_k_{}.npy'.format(k), (train_indices, val_indices, test_indices))\n",
    "\n",
    "    visualize_save_embedding(X, y, encoder, 'Concrete VAE Marker Visualization', path = viz_save_path + 'concrete_vae_markers_k_{}.png'.format(k), markers = concrete_vae_markers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "GNvaf3yvH2TK"
   },
   "outputs": [],
   "source": [
    "k = 50\n",
    "for tryy in range(1,num_times+1):\n",
    "    train_dataloader, val_dataloader, _, train_indices, val_indices, test_indices = split_data_into_dataloaders(X, y, 0.7, 0.1, num_workers = num_cores, batch_size = batch_size)\n",
    "    X_train = X[np.concatenate([train_indices, val_indices]), :]\n",
    "    y_train = y[np.concatenate([train_indices, val_indices])]\n",
    "    X_test = X[test_indices,:]\n",
    "    y_test = y[test_indices]\n",
    "\n",
    "    model = ConcreteVAE_NMSL(input_size, hidden_layer_size, z_size, k = k, t = global_t, bias = True, temperature_decay = 0.9, batch_norm = batch_norm)\n",
    "    tmp_path = model_save_path + 'concrete_vae_{}.ckpt'.format(tryy)\n",
    "    train_save_model(model, train_dataloader, val_dataloader, tmp_path, gpus=1, min_epochs = 25, max_epochs = 100, auto_lr = True, max_lr = 0.0001, early_stopping_patience = 3, \n",
    "                     lr_explore_mode = 'linear', num_lr_rates = 500, precision = precision)\n",
    "    concrete_vae_markers = model.markers().clone().cpu().detach().numpy()\n",
    "    \n",
    "\n",
    "    results = new_model_metrics(X_train, y_train, X_test, y_test, markers = concrete_vae_markers)\n",
    "    np.save(model_save_path + 'concrete_vae_results_{}.npy'.format(tryy), results)\n",
    "    np.save(model_save_path + 'concrete_vae_markers_{}.npy'.format(tryy), concrete_vae_markers)\n",
    "    np.save(model_save_path + 'experiment_data_folds/concrete_vae_indices_{}.npy'.format(tryy), (train_indices, val_indices, test_indices))\n",
    "\n",
    "    visualize_save_embedding(X, y, encoder, 'Concrete VAE Marker Visualization', path = viz_save_path + 'concrete_vae_markers_{}.png'.format(tryy), markers = concrete_vae_markers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9dAnqDekNLCa"
   },
   "source": [
    "## LassoNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9vmBqqA7OPgq"
   },
   "outputs": [],
   "source": [
    "dev = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j9IL88OwORCn"
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from lassonet import plot_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FzLGV4z4OJse"
   },
   "outputs": [],
   "source": [
    "k = 50\n",
    "for tryy in range(1,num_times+1):  \n",
    "    _, _, _, train_indices, val_indices, test_indices = split_data_into_dataloaders(X, y, 0.7, 0.1)\n",
    "    X_train = X[train_indices, :]\n",
    "    y_train = y[train_indices]\n",
    "    X_val = X[val_indices,:]\n",
    "    y_val = y[val_indices]\n",
    "    X_test = X[test_indices,:]\n",
    "    y_test = y[test_indices]\n",
    "    model = LassoNetClassifier(hidden_dims = (hidden_layer_size, hidden_layer_size, hidden_layer_size))\n",
    "    model.path(X_train, y_train, X_val = X_val, y_val = y_val)\n",
    "    lasso_net_markers = torch.argsort(model.feature_importances_, descending = True).cpu().numpy()[:k]\n",
    "    results = new_model_metrics(X_train, y_train, X_test, y_test, markers = lasso_net_markers)\n",
    "    np.save(model_save_path + 'lasso_net_results_{}.npy'.format(tryy), results)\n",
    "    np.save(model_save_path + 'lasso_net_markers_{}.npy'.format(tryy), lasso_net_markers)\n",
    "    np.save(model_save_path + 'experiment_data_folds/lasso_net_indices_{}.npy'.format(tryy), (train_indices, val_indices, test_indices))\n",
    "\n",
    "    visualize_save_embedding(X, y, encoder, 'LassoNet Marker Visualization', path = viz_save_path + 'lasso_net_markers_{}.png'.format(tryy), markers = lasso_net_markers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5cNG1XJsNNUv"
   },
   "outputs": [],
   "source": [
    "for k in k_range:\n",
    "    _, _, _, train_indices, val_indices, test_indices = split_data_into_dataloaders(X, y, 0.7, 0.1)\n",
    "    X_train = X[train_indices, :]\n",
    "    y_train = y[train_indices]\n",
    "    X_val = X[val_indices,:]\n",
    "    y_val = y[val_indices]\n",
    "    X_test = X[test_indices,:]\n",
    "    y_test = y[test_indices]\n",
    "    model = LassoNetClassifier(hidden_dims = (hidden_layer_size, hidden_layer_size, hidden_layer_size))\n",
    "    model.path(X_train, y_train, X_val = X_val, y_val = y_val)\n",
    "    lasso_net_markers = torch.argsort(model.feature_importances_, descending = True).cpu().numpy()[:k]\n",
    "    results = new_model_metrics(X_train, y_train, X_test, y_test, markers = lasso_net_markers)\n",
    "    np.save(model_save_path + 'lasso_net_results_k_{}.npy'.format(k), results)\n",
    "    np.save(model_save_path + 'lasso_net_markers_k_{}.npy'.format(k), lasso_net_markers)\n",
    "    np.save(model_save_path + 'experiment_data_folds/lasso_net_indices_k_{}.npy'.format(k), (train_indices, val_indices, test_indices))\n",
    "    visualize_save_embedding(X, y, encoder, 'LassoNet Marker Visualization', path = viz_save_path + 'lasso_net_markers_k_{}.png'.format(k), markers = lasso_net_markers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xSv5uYd5sH0h"
   },
   "source": [
    "## Get Model Metrics from KNNs Classifiers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZkhCV_uLsMdK"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uenGF6tGsTuY"
   },
   "outputs": [],
   "source": [
    "def generate_metrics_from_saved_files(X, y, folds_path, markers_path, classifier_model, save_path):\n",
    "    train_indices, val_indices, test_indices = np.load(folds_path, allow_pickle = True)\n",
    "    markers = np.load(markers_path, allow_pickle = True)\n",
    "    X_train = X[np.concatenate([train_indices, val_indices]), :]\n",
    "    y_train = y[np.concatenate([train_indices, val_indices])]\n",
    "    X_test = X[test_indices, :]\n",
    "    y_test = y[test_indices]\n",
    "    results = new_model_metrics(X_train, y_train, X_test, y_test, markers = markers, model = classifier_model)\n",
    "\n",
    "    np.save(save_path, results)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xe9IF6bXzkaB"
   },
   "outputs": [],
   "source": [
    "def batch_generate_metrics_from_saved_files(X, y, format_folds_path, format_markers_path, format_save_path):\n",
    "    for tryy in range(1, num_times+1):\n",
    "        classifier_model = KNeighborsClassifier()\n",
    "        generate_metrics_from_saved_files(X, y, format_folds_path.format(tryy), format_markers_path.format(tryy), classifier_model, format_save_path.format(tryy))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j5T6IH2eTU4C",
    "outputId": "c3c11a90-9a32-45ee-daf8-4e7ca4bc33de"
   },
   "outputs": [],
   "source": [
    "batch_generate_metrics_from_saved_files(X, y,\n",
    "                                  model_save_path+'experiment_data_folds/all_markers_indices_{}.npy',\n",
    "                                  model_save_path+'all_markers_{}.npy',\n",
    "                                  model_save_path+'all_markers_knn_results_{}.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ve2Y5gWu0Agu"
   },
   "outputs": [],
   "source": [
    "batch_generate_metrics_from_saved_files(X, y,\n",
    "                                  model_save_path+'experiment_data_folds/l1_vae_indices_{}.npy',\n",
    "                                  model_save_path+'l1_vae_markers_{}.npy',\n",
    "                                  model_save_path+'l1_vae_knn_results_{}.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rYoLncxoFLyR"
   },
   "outputs": [],
   "source": [
    "batch_generate_metrics_from_saved_files(X, y,\n",
    "                                  model_save_path+'experiment_data_folds/smash_rf_indices_{}.npy',\n",
    "                                  model_save_path+'smash_rf_markers_{}.npy',\n",
    "                                  model_save_path+'smash_rf_knn_results_{}.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J-0jS0d6FcCx"
   },
   "outputs": [],
   "source": [
    "batch_generate_metrics_from_saved_files(X, y,\n",
    "                                  model_save_path+'experiment_data_folds/smash_indices_{}.npy',\n",
    "                                  model_save_path+'smash_markers_{}.npy',\n",
    "                                  model_save_path+'smash_knn_results_{}.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vgB8eI-uHsZo"
   },
   "outputs": [],
   "source": [
    "batch_generate_metrics_from_saved_files(X, y,\n",
    "                                  model_save_path+'experiment_data_folds/rankcorr_indices_{}.npy',\n",
    "                                  model_save_path+'rankcorr_markers_{}.npy',\n",
    "                                  model_save_path+'rankcorr_knn_results_{}.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DgHuhfh7FqXu"
   },
   "outputs": [],
   "source": [
    "batch_generate_metrics_from_saved_files(X, y,\n",
    "                                  model_save_path+'experiment_data_folds/globalgate_vae_indices_{}.npy',\n",
    "                                  model_save_path+'globalgate_vae_markers_{}.npy',\n",
    "                                  model_save_path+'globalgate_vae_knn_results_{}.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IoEYnjQAF4yh"
   },
   "outputs": [],
   "source": [
    "batch_generate_metrics_from_saved_files(X, y,\n",
    "                                  model_save_path+'experiment_data_folds/marker_map_unsupervised_indices_{}.npy',\n",
    "                                  model_save_path+'marker_map_unsupervised_markers_{}.npy',\n",
    "                                  model_save_path+'marker_map_unsupervised_knn_results_{}.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R37cCcMjF6Dj"
   },
   "outputs": [],
   "source": [
    "batch_generate_metrics_from_saved_files(X, y,\n",
    "                                  model_save_path+'experiment_data_folds/marker_map_supervised_indices_{}.npy',\n",
    "                                  model_save_path+'marker_map_supervised_markers_{}.npy',\n",
    "                                  model_save_path+'marker_map_supervised_knn_results_{}.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9PlLkFOM2zA2"
   },
   "outputs": [],
   "source": [
    "batch_generate_metrics_from_saved_files(X, y,\n",
    "                                  model_save_path+'experiment_data_folds/marker_map_mixed_indices_{}.npy',\n",
    "                                  model_save_path+'marker_map_mixed_markers_{}.npy',\n",
    "                                  model_save_path+'marker_map_mixed_knn_results_{}.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pUGx03pcF6YI"
   },
   "outputs": [],
   "source": [
    "batch_generate_metrics_from_saved_files(X, y,\n",
    "                                  model_save_path+'experiment_data_folds/concrete_vae_indices_{}.npy',\n",
    "                                  model_save_path+'concrete_vae_markers_{}.npy',\n",
    "                                  model_save_path+'concrete_vae_knn_results_{}.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7VFkCKG_OwDY"
   },
   "outputs": [],
   "source": [
    "batch_generate_metrics_from_saved_files(X, y,\n",
    "                                  model_save_path+'experiment_data_folds/lasso_net_indices_{}.npy',\n",
    "                                  model_save_path+'lasso_net_markers_{}.npy',\n",
    "                                  model_save_path+'lasso_net_knn_results_{}.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h76JWN0AAlb9"
   },
   "source": [
    "### Generate the same metrics using the various K ranges instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i1fZEr5xF_Co"
   },
   "outputs": [],
   "source": [
    "# for looking at things that did one trial\n",
    "def batch_generate_metrics_from_saved_files_limited(X, y, format_folds_path, format_markers_path, format_save_path):\n",
    "    for k in k_range:\n",
    "        classifier_model = KNeighborsClassifier()\n",
    "        generate_metrics_from_saved_files(X, y, format_folds_path.format(k), format_markers_path.format(k), classifier_model, format_save_path.format(k))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c_Xz6Jf4A25y",
    "outputId": "d24d3d66-de35-4a6b-cde8-1bb3248a4ec8"
   },
   "outputs": [],
   "source": [
    "batch_generate_metrics_from_saved_files_limited(X, y,\n",
    "                                  model_save_path+'experiment_data_folds/l1_vae_indices_k_{}.npy',\n",
    "                                  model_save_path+'l1_vae_markers_k_{}.npy',\n",
    "                                  model_save_path+'l1_vae_knn_results_k_{}.npy')\n",
    "\n",
    "batch_generate_metrics_from_saved_files_limited(X, y,\n",
    "                                  model_save_path+'experiment_data_folds/smash_rf_indices_k_{}.npy',\n",
    "                                  model_save_path+'smash_rf_markers_k_{}.npy',\n",
    "                                  model_save_path+'smash_rf_knn_results_k_{}.npy')\n",
    "\n",
    "batch_generate_metrics_from_saved_files_limited(X, y,\n",
    "                                  model_save_path+'experiment_data_folds/smash_indices_k_{}.npy',\n",
    "                                  model_save_path+'smash_markers_k_{}.npy',\n",
    "                                  model_save_path+'smash_knn_results_k_{}.npy')\n",
    "\n",
    "batch_generate_metrics_from_saved_files_limited(X, y,\n",
    "                                  model_save_path+'experiment_data_folds/rankcorr_indices_k_{}.npy',\n",
    "                                  model_save_path+'rankcorr_markers_k_{}.npy',\n",
    "                                  model_save_path+'rankcorr_knn_results_k_{}.npy')\n",
    "\n",
    "batch_generate_metrics_from_saved_files_limited(X, y,\n",
    "                                  model_save_path+'experiment_data_folds/globalgate_vae_indices_k_{}.npy',\n",
    "                                  model_save_path+'globalgate_vae_markers_k_{}.npy',\n",
    "                                  model_save_path+'globalgate_vae_knn_results_k_{}.npy')\n",
    "\n",
    "\n",
    "batch_generate_metrics_from_saved_files_limited(X, y,\n",
    "                                  model_save_path+'experiment_data_folds/marker_map_unsupervised_indices_k_{}.npy',\n",
    "                                  model_save_path+'marker_map_unsupervised_markers_k_{}.npy',\n",
    "                                  model_save_path+'marker_map_unsupervised_knn_results_k_{}.npy')\n",
    "\n",
    "batch_generate_metrics_from_saved_files_limited(X, y,\n",
    "                                  model_save_path+'experiment_data_folds/marker_map_supervised_indices_k_{}.npy',\n",
    "                                  model_save_path+'marker_map_supervised_markers_k_{}.npy',\n",
    "                                  model_save_path+'marker_map_supervised_knn_results_k_{}.npy')\n",
    "\n",
    "batch_generate_metrics_from_saved_files_limited(X, y,\n",
    "                                  model_save_path+'experiment_data_folds/marker_map_mixed_indices_k_{}.npy',\n",
    "                                  model_save_path+'marker_map_mixed_markers_k_{}.npy',\n",
    "                                  model_save_path+'marker_map_mixed_knn_results_k_{}.npy')\n",
    "\n",
    "\n",
    "batch_generate_metrics_from_saved_files_limited(X, y,\n",
    "                                  model_save_path+'experiment_data_folds/concrete_vae_indices_k_{}.npy',\n",
    "                                  model_save_path+'concrete_vae_markers_k_{}.npy',\n",
    "                                  model_save_path+'concrete_vae_knn_results_k_{}.npy')\n",
    "\n",
    "batch_generate_metrics_from_saved_files_limited(X, y,\n",
    "                                  model_save_path+'experiment_data_folds/lasso_net_indices_k_{}.npy',\n",
    "                                  model_save_path+'lasso_net_markers_k_{}.npy',\n",
    "                                  model_save_path+'lasso_net_knn_results_k_{}.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ac3v6MHk6Ag_"
   },
   "source": [
    "# Results and Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hb9oLy6CdgNu"
   },
   "outputs": [],
   "source": [
    "k = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r49opYsbRZm0"
   },
   "source": [
    "## Accuracies and F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "onT-MVmoGfKO"
   },
   "outputs": [],
   "source": [
    "result_axis = [\n",
    " ('All Markers', 'all_markers_results_{}.npy', 'all_markers_knn_results_{}.npy'), \n",
    " ('L1 VAE', 'l1_vae_results_{}.npy', 'l1_vae_knn_results_{}.npy'),\n",
    " ('Smash RF', 'smash_rf_results_{}.npy', 'smash_rf_knn_results_{}.npy'),\n",
    " ('SMaSH DNN', 'smash_results_{}.npy', 'smash_knn_results_{}.npy'),\n",
    " ('RankCorr', 'rankcorr_results_{}.npy', 'rankcorr_knn_results_{}.npy'),\n",
    " ('Global Gate VAE', 'globalgate_vae_results_{}.npy', 'globalgate_vae_knn_results_{}.npy'),\n",
    " ('MarkerMap Unsupervised', 'marker_map_unsupervised_results_{}.npy', 'marker_map_unsupervised_knn_results_{}.npy'),\n",
    " ('MarkerMap Supervised', 'marker_map_supervised_results_{}.npy', 'marker_map_supervised_knn_results_{}.npy'),\n",
    " ('MarkerMap Mixed Supervision', 'marker_map_mixed_results_{}.npy', 'marker_map_mixed_knn_results_{}.npy'),\n",
    " ('Concrete VAE',  'concrete_vae_results_{}.npy', 'concrete_vae_knn_results_{}.npy'),\n",
    " ('LassoNet', 'lasso_net_results_{}.npy', 'lasso_net_knn_results_{}.npy')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7LLoa-WyKph2"
   },
   "outputs": [],
   "source": [
    "data_proto = []\n",
    "indices = []\n",
    "for axis in result_axis: \n",
    "    data_proto.append(model_variances(model_save_path + axis[1], num_times))\n",
    "    indices.append(axis[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390
    },
    "id": "t_IFm4JjBkfp",
    "outputId": "7c49c625-8848-4a4f-de5b-f221fe12c79e"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(data_proto, index = indices, \n",
    "             columns = ['Misclassification Mean', 'Weighted F1 Mean', 'Misclassification Standard Deviation', 'Weighted F1 Standard Deviation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oayy62ETBaj_"
   },
   "outputs": [],
   "source": [
    "data_proto = []\n",
    "indices = []\n",
    "for axis in result_axis: \n",
    "    data_proto.append(model_variances(model_save_path + axis[2], num_times))\n",
    "    indices.append(axis[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390
    },
    "id": "H7R_7QDnLRKV",
    "outputId": "c92edb81-ccbc-472d-b27a-16afd010bfb0"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(data_proto, index = indices, \n",
    "             columns = ['Misclassification Mean', 'Weighted F1 Mean', 'Misclassification Standard Deviation', 'Weighted F1 Standard Deviation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Brds9F5jRnYq"
   },
   "source": [
    "## Confusion Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RwaNGwBvxBBE"
   },
   "source": [
    "k = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XFnmZO_2TuOY"
   },
   "source": [
    "### All Markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "5P2RkoVKTwnm",
    "outputId": "91b5d46a-29c8-48d0-c047-eec502895ef0"
   },
   "outputs": [],
   "source": [
    "results =  np.load(model_save_path + 'all_markers_results_{}.npy'.format(1), allow_pickle = True)\n",
    "plot_confusion_matrix(results[2], encoder.classes_, title = 'All Markers Confusion Matrix', save_path = viz_save_path + 'all_markers_cm.pdf', cmap = 'icefire')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Lp6epw4Mzxe"
   },
   "source": [
    "### Smash RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Ig5MZump1Ag"
   },
   "outputs": [],
   "source": [
    "results =  np.load(model_save_path + 'smash_rf_results_{}.npy'.format(1), allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "SLkCmrh_qtSd",
    "outputId": "3052d918-de63-4069-bd96-e1ba0abe1bb5"
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(results[2], encoder.classes_, title = 'Smash Random Forest Confusion Matrix', save_path = viz_save_path + 'smash_rf_cm.pdf', cmap = 'icefire')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UoYdZvhYb9I5"
   },
   "source": [
    "### Smash DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V7ibTfpub8kT"
   },
   "outputs": [],
   "source": [
    "results =  np.load(model_save_path + 'smash_results_{}.npy'.format(1), allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "Bka70bpnb-44",
    "outputId": "e38047fc-1124-49c8-b897-7b09ee08ed6f"
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(results[2], encoder.classes_, title = 'Smash DNN Confusion Matrix', save_path = viz_save_path + 'smash_cm.pdf', cmap = 'icefire')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RoHIHsMhM1Jc"
   },
   "source": [
    "### RankCorr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "zHE1nVLnyJlY",
    "outputId": "939137b3-ce31-4c85-db49-b8d9036ccc57"
   },
   "outputs": [],
   "source": [
    "results =  np.load(model_save_path + 'rankcorr_results_{}.npy'.format(1), allow_pickle = True)\n",
    "plot_confusion_matrix(results[2], encoder.classes_, title = 'RankCorr Confusion Matrix', save_path = viz_save_path + 'rankcorr_cm.pdf', cmap = 'icefire')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qe0G8ulp3Cc1"
   },
   "source": [
    "### L1 VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "mba3I4gS3Fmb",
    "outputId": "76ab731c-6c24-4d25-e635-ab0a9ef25f61"
   },
   "outputs": [],
   "source": [
    "results =  np.load(model_save_path + 'l1_vae_results_{}.npy'.format(1), allow_pickle = True)\n",
    "plot_confusion_matrix(results[2], encoder.classes_, title = 'L1 VAE Confusion Matrix', save_path = viz_save_path + 'l1_vae_cm.pdf', cmap = 'icefire')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k-9W1yk1B4kK"
   },
   "source": [
    "### Global Gate VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "g5bZpPOvB6W6",
    "outputId": "6de41e93-6a6f-4719-8082-c78348b269a1"
   },
   "outputs": [],
   "source": [
    "results =  np.load(model_save_path + 'globalgate_vae_results_{}.npy'.format(1), allow_pickle = True)\n",
    "plot_confusion_matrix(results[2], encoder.classes_, title = 'GlobalGate VAE Confusion Matrix', save_path = viz_save_path + 'globalgate_vae_cm.pdf', cmap = 'icefire')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5DqEjpEaM22D"
   },
   "source": [
    "### Running MarkerMap Unsupervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "It6Bc65UyUM2",
    "outputId": "08d71917-4f9c-4572-93f0-09be5d8989e4"
   },
   "outputs": [],
   "source": [
    "results =  np.load(model_save_path + 'marker_map_unsupervised_results_{}.npy'.format(1), allow_pickle = True)\n",
    "plot_confusion_matrix(results[2], encoder.classes_, title = 'MarkerMap Unsupervised Confusion Matrix', save_path = viz_save_path + 'marker_map_unsupervised_cm.pdf', cmap = 'icefire')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "flI6ggosM-f8"
   },
   "source": [
    "### Running MarkerMap Supervised\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "DXrAepUb0F5G",
    "outputId": "240d3969-ced8-4ccf-debb-47a3054707ad"
   },
   "outputs": [],
   "source": [
    "results =  np.load(model_save_path + 'marker_map_supervised_results_{}.npy'.format(1), allow_pickle = True)\n",
    "plot_confusion_matrix(results[2], encoder.classes_, title = 'MarkerMap Supervised Confusion Matrix', save_path = viz_save_path + 'marker_map_supervised_cm.pdf', cmap = 'icefire')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T1Ek7wbf27oB"
   },
   "source": [
    "### MarkerMap Mixed Supervision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "j2ZP0B6X2_uo",
    "outputId": "636502c4-8a51-4cc5-dfd4-c1717e08c8f6"
   },
   "outputs": [],
   "source": [
    "results =  np.load(model_save_path + 'marker_map_mixed_results_{}.npy'.format(1), allow_pickle = True)\n",
    "plot_confusion_matrix(results[2], encoder.classes_, title = 'MarkerMap Mixed Supervision Confusion Matrix', save_path = viz_save_path + 'marker_map_mixed_cm.pdf', cmap = 'icefire')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yMJD3N0JM80q"
   },
   "source": [
    "### Concrete VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "ET_uNpJp0Ujo",
    "outputId": "196950dc-1acc-4890-f7a2-05fac111af5a"
   },
   "outputs": [],
   "source": [
    "results =  np.load(model_save_path + 'concrete_vae_results_{}.npy'.format(1), allow_pickle = True)\n",
    "plot_confusion_matrix(results[2], encoder.classes_, title = 'Concrete VAE Confusion Matrix', save_path = viz_save_path + 'concrete_vae_cm.pdf', cmap = 'icefire')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yp8khWQ7Ozym"
   },
   "source": [
    "## LassoNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "9Y1G52oPO0-j",
    "outputId": "12e58333-0f1d-4fd7-8bd1-c3c547e8b9aa"
   },
   "outputs": [],
   "source": [
    "results =  np.load(model_save_path + 'lasso_net_results_{}.npy'.format(1), allow_pickle = True)\n",
    "plot_confusion_matrix(results[2], encoder.classes_, title = 'LassoNet Confusion Matrix', save_path = viz_save_path + 'lasso_net_cm.pdf', cmap = 'icefire')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ABO87u_xiWIx"
   },
   "source": [
    "## Visualizing k on weighted f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 441
    },
    "id": "1tXxmGJakt2L",
    "outputId": "8b8725ea-a37c-46ab-eb64-672b7e1f7a5d"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize = (13, 6))\n",
    "\n",
    "#rf\n",
    "smash_rf_scores = []\n",
    "for k_i in k_range:\n",
    "    _, rep, _ = np.load(model_save_path + 'smash_rf_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    smash_rf_scores.append(rep['weighted avg']['f1-score'])\n",
    "\n",
    "\n",
    "smash_dnn_scores = []\n",
    "for k_i in k_range:\n",
    "    _, rep, _ = np.load(model_save_path + 'smash_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    smash_dnn_scores.append(rep['weighted avg']['f1-score'])\n",
    "\n",
    "rank_corr_scores = []\n",
    "for k_i in k_range:\n",
    "    _, rep, _ = np.load(model_save_path + 'rankcorr_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    rank_corr_scores.append(rep['weighted avg']['f1-score'])\n",
    "\n",
    "l1_vae_scores = []\n",
    "for k_i in k_range:\n",
    "    _, rep, _ = np.load(model_save_path + 'l1_vae_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    l1_vae_scores.append(rep['weighted avg']['f1-score'])\n",
    "\n",
    "globalgate_vae_scores = []\n",
    "for k_i in k_range:\n",
    "    _, rep, _ = np.load(model_save_path + 'globalgate_vae_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    globalgate_vae_scores.append(rep['weighted avg']['f1-score'])\n",
    "\n",
    "marker_map_unsupervised_scores = []\n",
    "for k_i in k_range:\n",
    "    _, rep, _ = np.load(model_save_path + 'marker_map_unsupervised_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    marker_map_unsupervised_scores.append(rep['weighted avg']['f1-score'])\n",
    "\n",
    "marker_map_supervised_scores = []\n",
    "for k_i in k_range:\n",
    "    _, rep, _ = np.load(model_save_path + 'marker_map_supervised_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    marker_map_supervised_scores.append(rep['weighted avg']['f1-score'])\n",
    "\n",
    "\n",
    "marker_map_mixed_scores = []\n",
    "for k_i in k_range:\n",
    "    _, rep, _ = np.load(model_save_path + 'marker_map_mixed_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    marker_map_mixed_scores.append(rep['weighted avg']['f1-score'])\n",
    "\n",
    "concrete_scores = []\n",
    "for k_i in k_range:\n",
    "    _, rep, _ = np.load(model_save_path + 'concrete_vae_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    concrete_scores.append(rep['weighted avg']['f1-score'])\n",
    "\n",
    "lasso_net_scores = []\n",
    "for k_i in k_range:\n",
    "    _, rep, _ = np.load(model_save_path + 'lasso_net_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    lasso_net_scores.append(rep['weighted avg']['f1-score'])\n",
    "\n",
    "scores = [smash_rf_scores, smash_dnn_scores, rank_corr_scores, l1_vae_scores, globalgate_vae_scores, marker_map_unsupervised_scores, marker_map_supervised_scores, \n",
    "          marker_map_mixed_scores, concrete_scores, lasso_net_scores]\n",
    "max_point = max([max(score) for score in scores])\n",
    "axs[0].plot(k_range, smash_rf_scores, label = 'Smash Random Forest', color = 'magenta', marker = 'o')\n",
    "#plt.plot(k_range, smash_dnn_scores, label = 'Smash DNN', marker = 'o')\n",
    "axs[0].plot(k_range, rank_corr_scores, label = 'Rank Corr', color = 'purple', marker = 'o')\n",
    "axs[0].plot(k_range, l1_vae_scores, label = 'L1 VAE', color = 'black', marker = 'o')\n",
    "#plt.plot(k_range, globalgate_vae_scores, label = 'Global Gumbel VAE', color = 'green', marker = 'o')\n",
    "axs[0].plot(k_range, marker_map_unsupervised_scores, label = 'MarkerMap Unsupervised', color = 'red', marker = 'o')\n",
    "axs[0].plot(k_range, marker_map_supervised_scores, label = 'MarkerMap Supervised', color = 'blue', marker = 'o')\n",
    "#plt.plot(k_range, marker_map_mixed_scores, label = 'RunningState VAE+Classifier', color = 'blue', marker = 'o')\n",
    "#plt.plot(k_range, concrete_scores, label = 'Concrete VAE', marker = 'o)\n",
    "axs[0].plot(k_range, lasso_net_scores, label = 'LassoNet', marker = 'o')\n",
    "axs[0].plot(k_range, max_point * np.ones(len(k_range)), linestyle = '--')\n",
    "axs[0].set_xlabel(\"Number of Markers Selected\")\n",
    "axs[0].set_xticks(k_range)\n",
    "axs[0].set_ylabel(r\"KNN Weighted $F_1$\")\n",
    "axs[0].legend()\n",
    "\n",
    "#knn\n",
    "\n",
    "smash_rf_scores = []\n",
    "for k_i in k_range:\n",
    "    _, rep, _ = np.load(model_save_path + 'smash_rf_knn_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    smash_rf_scores.append(rep['weighted avg']['f1-score'])\n",
    "\n",
    "\n",
    "smash_dnn_scores = []\n",
    "for k_i in k_range:\n",
    "    _, rep, _ = np.load(model_save_path + 'smash_knn_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    smash_dnn_scores.append(rep['weighted avg']['f1-score'])\n",
    "\n",
    "rank_corr_scores = []\n",
    "for k_i in k_range:\n",
    "    _, rep, _ = np.load(model_save_path + 'rankcorr_knn_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    rank_corr_scores.append(rep['weighted avg']['f1-score'])\n",
    "\n",
    "l1_vae_scores = []\n",
    "for k_i in k_range:\n",
    "    _, rep, _ = np.load(model_save_path + 'l1_vae_knn_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    l1_vae_scores.append(rep['weighted avg']['f1-score'])\n",
    "\n",
    "globalgate_vae_scores = []\n",
    "for k_i in k_range:\n",
    "    _, rep, _ = np.load(model_save_path + 'globalgate_vae_knn_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    globalgate_vae_scores.append(rep['weighted avg']['f1-score'])\n",
    "\n",
    "marker_map_unsupervised_scores = []\n",
    "for k_i in k_range:\n",
    "    _, rep, _ = np.load(model_save_path + 'marker_map_unsupervised_knn_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    marker_map_unsupervised_scores.append(rep['weighted avg']['f1-score'])\n",
    "\n",
    "marker_map_supervised_scores = []\n",
    "for k_i in k_range:\n",
    "    _, rep, _ = np.load(model_save_path + 'marker_map_supervised_knn_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    marker_map_supervised_scores.append(rep['weighted avg']['f1-score'])\n",
    "\n",
    "\n",
    "marker_map_mixed_scores = []\n",
    "for k_i in k_range:\n",
    "    _, rep, _ = np.load(model_save_path + 'marker_map_mixed_knn_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    marker_map_mixed_scores.append(rep['weighted avg']['f1-score'])\n",
    "\n",
    "concrete_scores = []\n",
    "for k_i in k_range:\n",
    "    _, rep, _ = np.load(model_save_path + 'concrete_vae_knn_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    concrete_scores.append(rep['weighted avg']['f1-score'])\n",
    "\n",
    "lasso_net_scores = []\n",
    "for k_i in k_range:\n",
    "    _, rep, _ = np.load(model_save_path + 'lasso_net_knn_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    lasso_net_scores.append(rep['weighted avg']['f1-score'])\n",
    "\n",
    "\n",
    "scores = [smash_rf_scores, smash_dnn_scores, rank_corr_scores, l1_vae_scores, globalgate_vae_scores, marker_map_unsupervised_scores, marker_map_supervised_scores, \n",
    "          marker_map_mixed_scores, concrete_scores, lasso_net_scores]\n",
    "max_point = max([max(score) for score in scores])\n",
    "axs[1].plot(k_range, smash_rf_scores, label = 'Smash Random Forest', color = 'magenta', marker = 'o')\n",
    "#plt.plot(k_range, smash_dnn_scores, label = 'Smash DNN', marker = 'o')\n",
    "axs[1].plot(k_range, rank_corr_scores, label = 'Rank Corr', color = 'purple', marker = 'o')\n",
    "axs[1].plot(k_range, l1_vae_scores, label = 'L1 VAE', color = 'black', marker = 'o')\n",
    "#plt.plot(k_range, globalgate_vae_scores, label = 'Global Gumbel VAE', color = 'green', marker = 'o')\n",
    "axs[1].plot(k_range, marker_map_unsupervised_scores, label = 'MarkerMap Unsupervised', color = 'red', marker = 'o')\n",
    "axs[1].plot(k_range, marker_map_supervised_scores, label = 'MarkerMap Supervised', color = 'blue', marker = 'o')\n",
    "#plt.plot(k_range, marker_map_mixed_scores, label = 'RunningState VAE+Classifier', color = 'blue', marker = 'o')\n",
    "#plt.plot(k_range, concrete_scores, label = 'Concrete VAE', marker = 'o)\n",
    "axs[1].plot(k_range, lasso_net_scores, label = 'LassoNet', marker = 'o')\n",
    "axs[1].plot(k_range, max_point * np.ones(len(k_range)), linestyle = '--')\n",
    "axs[1].set_xlabel(\"Number of Markers Selected\")\n",
    "axs[1].set_xticks(k_range)\n",
    "axs[1].set_ylabel(r\"KNN Weighted $F_1$\")\n",
    "axs[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(viz_save_path + 'CiteSeq_weighted_f1_vs_k.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2O5w1PUg2jlW"
   },
   "source": [
    "#### Include everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 441
    },
    "id": "LWAtQyWYnjDi",
    "outputId": "899acffc-7e71-45a9-813b-44955f61116c"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize = (13, 6))\n",
    "\n",
    "#rf\n",
    "smash_rf_scores = []\n",
    "for k_i in k_range:\n",
    "    _, rep, _ = np.load(model_save_path + 'smash_rf_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    smash_rf_scores.append(rep['weighted avg']['f1-score'])\n",
    "\n",
    "\n",
    "smash_dnn_scores = []\n",
    "for k_i in k_range:\n",
    "    _, rep, _ = np.load(model_save_path + 'smash_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    smash_dnn_scores.append(rep['weighted avg']['f1-score'])\n",
    "\n",
    "rank_corr_scores = []\n",
    "for k_i in k_range:\n",
    "    _, rep, _ = np.load(model_save_path + 'rankcorr_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    rank_corr_scores.append(rep['weighted avg']['f1-score'])\n",
    "\n",
    "l1_vae_scores = []\n",
    "for k_i in k_range:\n",
    "    _, rep, _ = np.load(model_save_path + 'l1_vae_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    l1_vae_scores.append(rep['weighted avg']['f1-score'])\n",
    "\n",
    "globalgate_vae_scores = []\n",
    "for k_i in k_range:\n",
    "    _, rep, _ = np.load(model_save_path + 'globalgate_vae_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    globalgate_vae_scores.append(rep['weighted avg']['f1-score'])\n",
    "\n",
    "marker_map_unsupervised_scores = []\n",
    "for k_i in k_range:\n",
    "    _, rep, _ = np.load(model_save_path + 'marker_map_unsupervised_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    marker_map_unsupervised_scores.append(rep['weighted avg']['f1-score'])\n",
    "\n",
    "marker_map_supervised_scores = []\n",
    "for k_i in k_range:\n",
    "    _, rep, _ = np.load(model_save_path + 'marker_map_supervised_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    marker_map_supervised_scores.append(rep['weighted avg']['f1-score'])\n",
    "\n",
    "\n",
    "marker_map_mixed_scores = []\n",
    "for k_i in k_range:\n",
    "    _, rep, _ = np.load(model_save_path + 'marker_map_mixed_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    marker_map_mixed_scores.append(rep['weighted avg']['f1-score'])\n",
    "\n",
    "concrete_scores = []\n",
    "for k_i in k_range:\n",
    "    _, rep, _ = np.load(model_save_path + 'concrete_vae_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    concrete_scores.append(rep['weighted avg']['f1-score'])\n",
    "\n",
    "lasso_net_scores = []\n",
    "for k_i in k_range:\n",
    "    _, rep, _ = np.load(model_save_path + 'lasso_net_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    lasso_net_scores.append(rep['weighted avg']['f1-score'])\n",
    "\n",
    "scores = [smash_rf_scores, smash_dnn_scores, rank_corr_scores, l1_vae_scores, globalgate_vae_scores, marker_map_unsupervised_scores, marker_map_supervised_scores, \n",
    "          marker_map_mixed_scores, concrete_scores, lasso_net_scores]\n",
    "max_point = max([max(score) for score in scores])\n",
    "axs[0].plot(k_range, smash_rf_scores, label = 'Smash Random Forest', color = 'magenta', marker = 'o')\n",
    "axs[0].plot(k_range, smash_dnn_scores, label = 'Smash DNN', marker = 'o')\n",
    "axs[0].plot(k_range, rank_corr_scores, label = 'Rank Corr', color = 'purple', marker = 'o')\n",
    "axs[0].plot(k_range, l1_vae_scores, label = 'L1 VAE', color = 'black', marker = 'o')\n",
    "axs[0].plot(k_range, globalgate_vae_scores, label = 'Global Gumbel VAE', color = 'green', marker = 'o')\n",
    "axs[0].plot(k_range, marker_map_unsupervised_scores, label = 'MarkerMap Unsupervised', color = 'red', marker = 'o')\n",
    "axs[0].plot(k_range, marker_map_supervised_scores, label = 'MarkerMap Supervised', color = 'blue', marker = 'o')\n",
    "axs[0].plot(k_range, marker_map_mixed_scores, label = 'MarkerMap Mixed Supervision', color = 'blue', marker = 'o')\n",
    "axs[0].plot(k_range, concrete_scores, label = 'Concrete VAE', marker = 'o')\n",
    "axs[0].plot(k_range, lasso_net_scores, label = 'LassoNet', marker = 'o')\n",
    "axs[0].plot(k_range, max_point * np.ones(len(k_range)), linestyle = '--')\n",
    "axs[0].set_xlabel(\"Number of Markers Selected\")\n",
    "axs[0].set_xticks(k_range)\n",
    "axs[0].set_ylabel(r\"KNN Weighted $F_1$\")\n",
    "axs[0].legend()\n",
    "\n",
    "#knn\n",
    "\n",
    "smash_rf_scores = []\n",
    "for k_i in k_range:\n",
    "    _, rep, _ = np.load(model_save_path + 'smash_rf_knn_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    smash_rf_scores.append(rep['weighted avg']['f1-score'])\n",
    "\n",
    "\n",
    "smash_dnn_scores = []\n",
    "for k_i in k_range:\n",
    "    _, rep, _ = np.load(model_save_path + 'smash_knn_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    smash_dnn_scores.append(rep['weighted avg']['f1-score'])\n",
    "\n",
    "rank_corr_scores = []\n",
    "for k_i in k_range:\n",
    "    _, rep, _ = np.load(model_save_path + 'rankcorr_knn_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    rank_corr_scores.append(rep['weighted avg']['f1-score'])\n",
    "\n",
    "l1_vae_scores = []\n",
    "for k_i in k_range:\n",
    "    _, rep, _ = np.load(model_save_path + 'l1_vae_knn_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    l1_vae_scores.append(rep['weighted avg']['f1-score'])\n",
    "\n",
    "globalgate_vae_scores = []\n",
    "for k_i in k_range:\n",
    "    _, rep, _ = np.load(model_save_path + 'globalgate_vae_knn_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    globalgate_vae_scores.append(rep['weighted avg']['f1-score'])\n",
    "\n",
    "marker_map_unsupervised_scores = []\n",
    "for k_i in k_range:\n",
    "    _, rep, _ = np.load(model_save_path + 'marker_map_unsupervised_knn_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    marker_map_unsupervised_scores.append(rep['weighted avg']['f1-score'])\n",
    "\n",
    "marker_map_supervised_scores = []\n",
    "for k_i in k_range:\n",
    "    _, rep, _ = np.load(model_save_path + 'marker_map_supervised_knn_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    marker_map_supervised_scores.append(rep['weighted avg']['f1-score'])\n",
    "\n",
    "\n",
    "marker_map_mixed_scores = []\n",
    "for k_i in k_range:\n",
    "    _, rep, _ = np.load(model_save_path + 'marker_map_mixed_knn_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    marker_map_mixed_scores.append(rep['weighted avg']['f1-score'])\n",
    "\n",
    "concrete_scores = []\n",
    "for k_i in k_range:\n",
    "    _, rep, _ = np.load(model_save_path + 'concrete_vae_knn_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    concrete_scores.append(rep['weighted avg']['f1-score'])\n",
    "\n",
    "lasso_net_scores = []\n",
    "for k_i in k_range:\n",
    "    _, rep, _ = np.load(model_save_path + 'lasso_net_knn_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    lasso_net_scores.append(rep['weighted avg']['f1-score'])\n",
    "\n",
    "\n",
    "scores = [smash_rf_scores, smash_dnn_scores, rank_corr_scores, l1_vae_scores, globalgate_vae_scores, marker_map_unsupervised_scores, marker_map_supervised_scores, \n",
    "          marker_map_mixed_scores, concrete_scores, lasso_net_scores]\n",
    "max_point = max([max(score) for score in scores])\n",
    "axs[1].plot(k_range, smash_rf_scores, label = 'Smash Random Forest', color = 'magenta', marker = 'o')\n",
    "axs[1].plot(k_range, smash_dnn_scores, label = 'Smash DNN', marker = 'o')\n",
    "axs[1].plot(k_range, rank_corr_scores, label = 'Rank Corr', color = 'purple', marker = 'o')\n",
    "axs[1].plot(k_range, l1_vae_scores, label = 'L1 VAE', color = 'black', marker = 'o')\n",
    "axs[1].plot(k_range, globalgate_vae_scores, label = 'Global Gumbel VAE', color = 'green', marker = 'o')\n",
    "axs[1].plot(k_range, marker_map_unsupervised_scores, label = 'MarkerMap Unsupervised', color = 'red', marker = 'o')\n",
    "axs[1].plot(k_range, marker_map_supervised_scores, label = 'MarkerMap Supervised', color = 'blue', marker = 'o')\n",
    "axs[1].plot(k_range, marker_map_mixed_scores, label = 'MarkerMap Mixed Supervision', color = 'blue', marker = 'o')\n",
    "axs[1].plot(k_range, concrete_scores, label = 'Concrete VAE', marker = 'o')\n",
    "axs[1].plot(k_range, lasso_net_scores, label = 'LassoNet', marker = 'o')\n",
    "axs[1].plot(k_range, max_point * np.ones(len(k_range)), linestyle = '--')\n",
    "axs[1].set_xlabel(\"Number of Markers Selected\")\n",
    "axs[1].set_xticks(k_range)\n",
    "axs[1].set_ylabel(r\"KNN Weighted $F_1$\")\n",
    "axs[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(viz_save_path + 'CiteSeq_weighted_f1_vs_k_all.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fMzYyOccoK6N"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BB1trf3SynWL"
   },
   "source": [
    "### Do Misclassification now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 441
    },
    "id": "4odGWzjCbElD",
    "outputId": "4750d090-dd39-456b-d21e-dc7df9cd08a2"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize = (13, 6))\n",
    "# random forest\n",
    "smash_rf_scores = []\n",
    "for k_i in k_range:\n",
    "    m, rep, _ = np.load(model_save_path + 'smash_rf_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    smash_rf_scores.append(m)\n",
    "\n",
    "smash_dnn_scores = []\n",
    "for k_i in k_range:\n",
    "    m, rep, _ = np.load(model_save_path + 'smash_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    smash_dnn_scores.append(m)\n",
    "\n",
    "rank_corr_scores = []\n",
    "for k_i in k_range:\n",
    "    m, rep, _ = np.load(model_save_path + 'rankcorr_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    rank_corr_scores.append(m)\n",
    "\n",
    "l1_vae_scores = []\n",
    "for k_i in k_range:\n",
    "    m, rep, _ = np.load(model_save_path + 'l1_vae_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    l1_vae_scores.append(m)\n",
    "\n",
    "globalgate_vae_scores = []\n",
    "for k_i in k_range:\n",
    "    m, rep, _ = np.load(model_save_path + 'globalgate_vae_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    globalgate_vae_scores.append(m)\n",
    "\n",
    "marker_map_unsupervised_scores = []\n",
    "for k_i in k_range:\n",
    "    m, rep, _ = np.load(model_save_path + 'marker_map_unsupervised_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    marker_map_unsupervised_scores.append(m)\n",
    "\n",
    "marker_map_supervised_scores = []\n",
    "for k_i in k_range:\n",
    "    m, rep, _ = np.load(model_save_path + 'marker_map_supervised_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    marker_map_supervised_scores.append(m)\n",
    "\n",
    "marker_map_mixed_scores = []\n",
    "for k_i in k_range:\n",
    "    m, rep, _ = np.load(model_save_path + 'marker_map_mixed_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    marker_map_mixed_scores.append(m)\n",
    "\n",
    "concrete_scores = []\n",
    "for k_i in k_range:\n",
    "    m, rep, _ = np.load(model_save_path + 'concrete_vae_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    concrete_scores.append(m)\n",
    "\n",
    "lasso_net_scores = []\n",
    "for k_i in k_range:\n",
    "    m, rep, _ = np.load(model_save_path + 'lasso_net_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    lasso_net_scores.append(m)\n",
    "    \n",
    "scores = [smash_rf_scores, smash_dnn_scores, rank_corr_scores, l1_vae_scores, globalgate_vae_scores, marker_map_unsupervised_scores, marker_map_supervised_scores, \n",
    "          marker_map_mixed_scores, concrete_scores, lasso_net_scores]\n",
    "min_point = min([min(score) for score in scores])\n",
    "axs[0].plot(k_range, smash_rf_scores, label = 'Smash Random Forest', color = 'magenta', marker = 'o')\n",
    "#plt.plot(k_range, smash_dnn_scores, label = 'Smash DNN', marker = 'o')\n",
    "axs[0].plot(k_range, rank_corr_scores, label = 'Rank Corr', color = 'purple', marker = 'o')\n",
    "axs[0].plot(k_range, l1_vae_scores, label = 'L1 VAE', color = 'black', marker = 'o')\n",
    "#plt.plot(k_range, globalgate_vae_scores, label = 'Global Gumbel VAE', color = 'green', marker = 'o')\n",
    "axs[0].plot(k_range, marker_map_unsupervised_scores, label = 'MarkerMap Unsupervised', color = 'red', marker = 'o')\n",
    "axs[0].plot(k_range, marker_map_supervised_scores, label = 'MarkerMap Supervised', color = 'blue', marker = 'o')\n",
    "#plt.plot(k_range, marker_map_mixed_scores, label = 'RunningState VAE+Classifier', color = 'blue', marker = 'o')\n",
    "#plt.plot(k_range, concrete_scores, label = 'Concrete VAE', marker = 'o)\n",
    "axs[0].plot(k_range, lasso_net_scores, label = 'LassoNet', marker = 'o')\n",
    "axs[0].plot(k_range, min_point * np.ones(len(k_range)), linestyle = '--')\n",
    "axs[0].set_xlabel(\"Number of Markers Selected\")\n",
    "axs[0].set_xticks(k_range)\n",
    "axs[0].set_ylabel(\"RF Misclassification Rate\")\n",
    "axs[0].legend()\n",
    "\n",
    "# knn\n",
    "smash_rf_scores = []\n",
    "for k_i in k_range:\n",
    "    m, rep, _ = np.load(model_save_path + 'smash_rf_knn_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    smash_rf_scores.append(m)\n",
    "\n",
    "smash_dnn_scores = []\n",
    "for k_i in k_range:\n",
    "    m, rep, _ = np.load(model_save_path + 'smash_knn_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    smash_dnn_scores.append(m)\n",
    "\n",
    "rank_corr_scores = []\n",
    "for k_i in k_range:\n",
    "    m, rep, _ = np.load(model_save_path + 'rankcorr_knn_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    rank_corr_scores.append(m)\n",
    "\n",
    "l1_vae_scores = []\n",
    "for k_i in k_range:\n",
    "    m, rep, _ = np.load(model_save_path + 'l1_vae_knn_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    l1_vae_scores.append(m)\n",
    "\n",
    "globalgate_vae_scores = []\n",
    "for k_i in k_range:\n",
    "    m, rep, _ = np.load(model_save_path + 'globalgate_vae_knn_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    globalgate_vae_scores.append(m)\n",
    "\n",
    "marker_map_unsupervised_scores = []\n",
    "for k_i in k_range:\n",
    "    m, rep, _ = np.load(model_save_path + 'marker_map_unsupervised_knn_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    marker_map_unsupervised_scores.append(m)\n",
    "\n",
    "marker_map_supervised_scores = []\n",
    "for k_i in k_range:\n",
    "    m, rep, _ = np.load(model_save_path + 'marker_map_supervised_knn_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    marker_map_supervised_scores.append(m)\n",
    "\n",
    "marker_map_mixed_scores = []\n",
    "for k_i in k_range:\n",
    "    m, rep, _ = np.load(model_save_path + 'marker_map_mixed_knn_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    marker_map_mixed_scores.append(m)\n",
    "\n",
    "concrete_scores = []\n",
    "for k_i in k_range:\n",
    "    m, rep, _ = np.load(model_save_path + 'concrete_vae_knn_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    concrete_scores.append(m)\n",
    "\n",
    "lasso_net_scores = []\n",
    "for k_i in k_range:\n",
    "    m, rep, _ = np.load(model_save_path + 'lasso_net_knn_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    lasso_net_scores.append(m)\n",
    "\n",
    "scores = [smash_rf_scores, smash_dnn_scores, rank_corr_scores, l1_vae_scores, globalgate_vae_scores, marker_map_unsupervised_scores, marker_map_supervised_scores, \n",
    "          marker_map_mixed_scores, concrete_scores, lasso_net_scores]\n",
    "min_point = min([min(score) for score in scores])\n",
    "axs[1].plot(k_range, smash_rf_scores, label = 'Smash Random Forest', color = 'magenta', marker = 'o')\n",
    "#plt.plot(k_range, smash_dnn_scores, label = 'Smash DNN', marker = 'o')\n",
    "axs[1].plot(k_range, rank_corr_scores, label = 'Rank Corr', color = 'purple', marker = 'o')\n",
    "axs[1].plot(k_range, l1_vae_scores, label = 'L1 VAE', color = 'black', marker = 'o')\n",
    "#plt.plot(k_range, globalgate_vae_scores, label = 'Global Gumbel VAE', color = 'green', marker = 'o')\n",
    "axs[1].plot(k_range, marker_map_unsupervised_scores, label = 'MarkerMap Unsupervised', color = 'red', marker = 'o')\n",
    "axs[1].plot(k_range, marker_map_supervised_scores, label = 'MarkerMap Supervised', color = 'blue', marker = 'o')\n",
    "#plt.plot(k_range, marker_map_mixed_scores, label = 'RunningState VAE+Classifier', color = 'blue', marker = 'o')\n",
    "#plt.plot(k_range, concrete_scores, label = 'Concrete VAE', marker = 'o)\n",
    "axs[1].plot(k_range, lasso_net_scores, label = 'LassoNet', marker = 'o')\n",
    "axs[1].plot(k_range, min_point * np.ones(len(k_range)), linestyle = '--')\n",
    "axs[1].set_xlabel(\"Number of Markers Selected\")\n",
    "axs[1].set_xticks(k_range)\n",
    "axs[1].set_ylabel(\"KNN Misclassification Rate\")\n",
    "axs[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(viz_save_path + 'CiteSeq_misclassification_vs_k.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dMy_ew9pt-wX"
   },
   "source": [
    "##### Include everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 441
    },
    "id": "03Tiy6XQuAk1",
    "outputId": "a87387c1-e9c0-4499-8f6e-4adae8826505"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize = (13, 6))\n",
    "# random forest\n",
    "smash_rf_scores = []\n",
    "for k_i in k_range:\n",
    "    m, rep, _ = np.load(model_save_path + 'smash_rf_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    smash_rf_scores.append(m)\n",
    "\n",
    "smash_dnn_scores = []\n",
    "for k_i in k_range:\n",
    "    m, rep, _ = np.load(model_save_path + 'smash_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    smash_dnn_scores.append(m)\n",
    "\n",
    "rank_corr_scores = []\n",
    "for k_i in k_range:\n",
    "    m, rep, _ = np.load(model_save_path + 'rankcorr_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    rank_corr_scores.append(m)\n",
    "\n",
    "l1_vae_scores = []\n",
    "for k_i in k_range:\n",
    "    m, rep, _ = np.load(model_save_path + 'l1_vae_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    l1_vae_scores.append(m)\n",
    "\n",
    "globalgate_vae_scores = []\n",
    "for k_i in k_range:\n",
    "    m, rep, _ = np.load(model_save_path + 'globalgate_vae_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    globalgate_vae_scores.append(m)\n",
    "\n",
    "marker_map_unsupervised_scores = []\n",
    "for k_i in k_range:\n",
    "    m, rep, _ = np.load(model_save_path + 'marker_map_unsupervised_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    marker_map_unsupervised_scores.append(m)\n",
    "\n",
    "marker_map_supervised_scores = []\n",
    "for k_i in k_range:\n",
    "    m, rep, _ = np.load(model_save_path + 'marker_map_supervised_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    marker_map_supervised_scores.append(m)\n",
    "\n",
    "marker_map_mixed_scores = []\n",
    "for k_i in k_range:\n",
    "    m, rep, _ = np.load(model_save_path + 'marker_map_mixed_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    marker_map_mixed_scores.append(m)\n",
    "\n",
    "concrete_scores = []\n",
    "for k_i in k_range:\n",
    "    m, rep, _ = np.load(model_save_path + 'concrete_vae_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    concrete_scores.append(m)\n",
    "\n",
    "lasso_net_scores = []\n",
    "for k_i in k_range:\n",
    "    m, rep, _ = np.load(model_save_path + 'lasso_net_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    lasso_net_scores.append(m)\n",
    "    \n",
    "scores = [smash_rf_scores, smash_dnn_scores, rank_corr_scores, l1_vae_scores, globalgate_vae_scores, marker_map_unsupervised_scores, marker_map_supervised_scores, \n",
    "          marker_map_mixed_scores, concrete_scores, lasso_net_scores]\n",
    "min_point = min([min(score) for score in scores])\n",
    "axs[0].plot(k_range, smash_rf_scores, label = 'Smash Random Forest', color = 'magenta', marker = 'o')\n",
    "axs[0].plot(k_range, smash_dnn_scores, label = 'Smash DNN', marker = 'o')\n",
    "axs[0].plot(k_range, rank_corr_scores, label = 'Rank Corr', color = 'purple', marker = 'o')\n",
    "axs[0].plot(k_range, l1_vae_scores, label = 'L1 VAE', color = 'black', marker = 'o')\n",
    "axs[0].plot(k_range, globalgate_vae_scores, label = 'Global Gumbel VAE', color = 'green', marker = 'o')\n",
    "axs[0].plot(k_range, marker_map_unsupervised_scores, label = 'MarkerMap Unsupervised', color = 'red', marker = 'o')\n",
    "axs[0].plot(k_range, marker_map_supervised_scores, label = 'MarkerMap Supervised', color = 'blue', marker = 'o')\n",
    "axs[0].plot(k_range, marker_map_mixed_scores, label = 'MarkerMap Mixed Supervision', color = 'blue', marker = 'o')\n",
    "axs[0].plot(k_range, concrete_scores, label = 'Concrete VAE', marker = 'o')\n",
    "axs[0].plot(k_range, lasso_net_scores, label = 'LassoNet', marker = 'o')\n",
    "axs[0].plot(k_range, min_point * np.ones(len(k_range)), linestyle = '--')\n",
    "axs[0].set_xlabel(\"Number of Markers Selected\")\n",
    "axs[0].set_xticks(k_range)\n",
    "axs[0].set_ylabel(\"RF Misclassification Rate\")\n",
    "axs[0].legend()\n",
    "\n",
    "# knn\n",
    "smash_rf_scores = []\n",
    "for k_i in k_range:\n",
    "    m, rep, _ = np.load(model_save_path + 'smash_rf_knn_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    smash_rf_scores.append(m)\n",
    "\n",
    "smash_dnn_scores = []\n",
    "for k_i in k_range:\n",
    "    m, rep, _ = np.load(model_save_path + 'smash_knn_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    smash_dnn_scores.append(m)\n",
    "\n",
    "rank_corr_scores = []\n",
    "for k_i in k_range:\n",
    "    m, rep, _ = np.load(model_save_path + 'rankcorr_knn_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    rank_corr_scores.append(m)\n",
    "\n",
    "l1_vae_scores = []\n",
    "for k_i in k_range:\n",
    "    m, rep, _ = np.load(model_save_path + 'l1_vae_knn_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    l1_vae_scores.append(m)\n",
    "\n",
    "globalgate_vae_scores = []\n",
    "for k_i in k_range:\n",
    "    m, rep, _ = np.load(model_save_path + 'globalgate_vae_knn_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    globalgate_vae_scores.append(m)\n",
    "\n",
    "marker_map_unsupervised_scores = []\n",
    "for k_i in k_range:\n",
    "    m, rep, _ = np.load(model_save_path + 'marker_map_unsupervised_knn_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    marker_map_unsupervised_scores.append(m)\n",
    "\n",
    "marker_map_supervised_scores = []\n",
    "for k_i in k_range:\n",
    "    m, rep, _ = np.load(model_save_path + 'marker_map_supervised_knn_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    marker_map_supervised_scores.append(m)\n",
    "\n",
    "marker_map_mixed_scores = []\n",
    "for k_i in k_range:\n",
    "    m, rep, _ = np.load(model_save_path + 'marker_map_mixed_knn_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    marker_map_mixed_scores.append(m)\n",
    "\n",
    "concrete_scores = []\n",
    "for k_i in k_range:\n",
    "    m, rep, _ = np.load(model_save_path + 'concrete_vae_knn_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    concrete_scores.append(m)\n",
    "\n",
    "lasso_net_scores = []\n",
    "for k_i in k_range:\n",
    "    m, rep, _ = np.load(model_save_path + 'lasso_net_knn_results_k_{}.npy'.format(k_i), allow_pickle = True)\n",
    "    lasso_net_scores.append(m)\n",
    "\n",
    "scores = [smash_rf_scores, smash_dnn_scores, rank_corr_scores, l1_vae_scores, globalgate_vae_scores, marker_map_unsupervised_scores, marker_map_supervised_scores, \n",
    "          marker_map_mixed_scores, concrete_scores, lasso_net_scores]\n",
    "min_point = min([min(score) for score in scores])\n",
    "axs[1].plot(k_range, smash_rf_scores, label = 'Smash Random Forest', color = 'magenta', marker = 'o')\n",
    "axs[1].plot(k_range, smash_dnn_scores, label = 'Smash DNN', marker = 'o')\n",
    "axs[1].plot(k_range, rank_corr_scores, label = 'Rank Corr', color = 'purple', marker = 'o')\n",
    "axs[1].plot(k_range, l1_vae_scores, label = 'L1 VAE', color = 'black', marker = 'o')\n",
    "axs[1].plot(k_range, globalgate_vae_scores, label = 'Global Gumbel VAE', color = 'green', marker = 'o')\n",
    "axs[1].plot(k_range, marker_map_unsupervised_scores, label = 'MarkerMap Unsupervised', color = 'red', marker = 'o')\n",
    "axs[1].plot(k_range, marker_map_supervised_scores, label = 'MarkerMap Supervised', color = 'blue', marker = 'o')\n",
    "axs[1].plot(k_range, marker_map_mixed_scores, label = 'MarkerMap Mixed Supervision', color = 'blue', marker = 'o')\n",
    "axs[1].plot(k_range, concrete_scores, label = 'Concrete VAE', marker = 'o')\n",
    "axs[1].plot(k_range, lasso_net_scores, label = 'LassoNet', marker = 'o')\n",
    "axs[1].plot(k_range, min_point * np.ones(len(k_range)), linestyle = '--')\n",
    "axs[1].set_xlabel(\"Number of Markers Selected\")\n",
    "axs[1].set_xticks(k_range)\n",
    "axs[1].set_ylabel(\"KNN Misclassification Rate\")\n",
    "axs[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(viz_save_path + 'CiteSeq_misclassification_vs_k_all.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KMSx3iG07eLP"
   },
   "source": [
    "## Visualize Marker Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2u-AbmG5pSd9"
   },
   "source": [
    "### Smash RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KwxklfWUpRjE"
   },
   "outputs": [],
   "source": [
    "smash_rf_markers = {}\n",
    "smash_rf_f1 = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I6gMZ8q5ppfU"
   },
   "outputs": [],
   "source": [
    "for k in k_range:\n",
    "    train_indices, val_indices, test_indices = np.load(model_save_path + 'experiment_data_folds/smash_rf_indices_k_{}.npy'.format(k), allow_pickle = True)\n",
    "    misclass_rate, test_rep, cm = np.load(model_save_path + 'smash_rf_results_k_{}.npy'.format(k), allow_pickle=True)\n",
    "    weighted_f1_score = test_rep['weighted avg']['f1-score']\n",
    "    markers = np.load(model_save_path + 'smash_rf_markers_k_{}.npy'.format(k), allow_pickle = True)\n",
    "    marker_data = np.zeros(X.shape[1])\n",
    "    marker_data[markers] = 1\n",
    "    smash_rf_markers[k] = marker_data\n",
    "    smash_rf_f1[k] = weighted_f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ac7iAy8urIf-"
   },
   "source": [
    "### Smash DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m1UsZj-7rKBb"
   },
   "outputs": [],
   "source": [
    "smash_dnn_markers = {}\n",
    "smash_dnn_f1 = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QIU4Y-KrMPRX"
   },
   "outputs": [],
   "source": [
    "for k in k_range:\n",
    "    train_indices, val_indices, test_indices = np.load(model_save_path + 'experiment_data_folds/smash_indices_k_{}.npy'.format(k), allow_pickle = True)\n",
    "    misclass_rate, test_rep, cm = np.load(model_save_path + 'smash_results_k_{}.npy'.format(k), allow_pickle=True)\n",
    "    weighted_f1_score = test_rep['weighted avg']['f1-score']\n",
    "    markers = np.load(model_save_path + 'smash_markers_k_{}.npy'.format(k), allow_pickle = True)\n",
    "    marker_data = np.zeros(X.shape[1])\n",
    "    marker_data[markers] = 1\n",
    "    smash_dnn_markers[k] = marker_data\n",
    "    smash_dnn_f1[k] = weighted_f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wp5alGY9RpbD"
   },
   "source": [
    "### RankCorr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ROdpSzyRtcP"
   },
   "outputs": [],
   "source": [
    "rankcorr_markers ={}\n",
    "rankcorr_f1 = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0aQpJN5pRs3E"
   },
   "outputs": [],
   "source": [
    "for k in k_range:\n",
    "    train_indices, val_indices, test_indices = np.load(model_save_path + 'experiment_data_folds/rankcorr_indices_k_{}.npy'.format(k), allow_pickle = True)\n",
    "    misclass_rate, test_rep, cm = np.load(model_save_path + 'rankcorr_results_k_{}.npy'.format(k), allow_pickle=True)\n",
    "    weighted_f1_score = test_rep['weighted avg']['f1-score']\n",
    "    markers = np.load(model_save_path + 'rankcorr_markers_k_{}.npy'.format(k), allow_pickle = True)\n",
    "    marker_data = np.zeros(X.shape[1])\n",
    "    marker_data[markers] = 1\n",
    "    rankcorr_markers[k] = marker_data\n",
    "    rankcorr_f1[k] = weighted_f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qR8QV61n7lwL"
   },
   "source": [
    "### L1 VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XfpoYMg8U-Nw"
   },
   "outputs": [],
   "source": [
    "l1_vae_markers = {}\n",
    "l1_vae_f1 = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UqeW4JxfSuy7"
   },
   "outputs": [],
   "source": [
    "for k in k_range:\n",
    "    train_indices, val_indices, test_indices = np.load(model_save_path + 'experiment_data_folds/l1_vae_indices_k_{}.npy'.format(k), allow_pickle = True)\n",
    "    X_train = X[train_indices, :]\n",
    "    feature_std = np.apply_along_axis(np.std, 0, X_train)\n",
    "    misclass_rate, test_rep, cm = np.load(model_save_path + 'l1_vae_results_k_{}.npy'.format(k), allow_pickle=True)\n",
    "    weighted_f1_score = test_rep['weighted avg']['f1-score']\n",
    "\n",
    "    model = load_model(VAE_l1_diag, model_save_path + 'l1_vae_k_{}.ckpt'.format(k))\n",
    "    with torch.no_grad():\n",
    "        markers = model.markers(feature_std, k)\n",
    "    marker_data = np.zeros(X.shape[1])\n",
    "    marker_data[markers] = 1\n",
    "    l1_vae_markers[k] = marker_data\n",
    "    l1_vae_f1[k] = weighted_f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qF_QXRhNSmYl"
   },
   "source": [
    "### GlobalGate VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-m_D7aRKpJrC"
   },
   "outputs": [],
   "source": [
    "globalgate_vae_markers = {}\n",
    "globalgate_vae_f1 = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ss094u4jT9m-"
   },
   "outputs": [],
   "source": [
    "for k in k_range:\n",
    "    train_indices, val_indices, test_indices = np.load(model_save_path + 'experiment_data_folds/globalgate_vae_indices_k_{}.npy'.format(k), allow_pickle = True)\n",
    "    misclass_rate, test_rep, cm = np.load(model_save_path + 'globalgate_vae_results_k_{}.npy'.format(k), allow_pickle=True)\n",
    "    weighted_f1_score = test_rep['weighted avg']['f1-score']\n",
    "    markers = np.load(model_save_path + 'globalgate_vae_markers_k_{}.npy'.format(k), allow_pickle = True)\n",
    "    marker_data = np.zeros(X.shape[1])\n",
    "    marker_data[markers] = 1\n",
    "    globalgate_vae_markers[k] = marker_data\n",
    "    globalgate_vae_f1[k] = weighted_f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UEBZF_68W-QS"
   },
   "source": [
    "### MarkerMap Unsupervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UaHgSnAQW6Tv"
   },
   "outputs": [],
   "source": [
    "marker_map_unsupervised_markers = {}\n",
    "marker_map_unsupervised_f1 = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FmMnQ-qJXGT2"
   },
   "outputs": [],
   "source": [
    "for k in k_range:\n",
    "    train_indices, val_indices, test_indices = np.load(model_save_path + 'experiment_data_folds/marker_map_unsupervised_indices_k_{}.npy'.format(k), allow_pickle = True)\n",
    "    misclass_rate, test_rep, cm = np.load(model_save_path + 'marker_map_unsupervised_results_k_{}.npy'.format(k), allow_pickle=True)\n",
    "    weighted_f1_score = test_rep['weighted avg']['f1-score']\n",
    "    markers = np.load(model_save_path + 'marker_map_unsupervised_markers_k_{}.npy'.format(k), allow_pickle = True)\n",
    "    marker_data = np.zeros(X.shape[1])\n",
    "    marker_data[markers] = 1\n",
    "    marker_map_unsupervised_markers[k] = marker_data\n",
    "    marker_map_unsupervised_f1[k] = weighted_f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZytVfucNaK52"
   },
   "source": [
    "### RunningState Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HvgPSutyaOB0"
   },
   "outputs": [],
   "source": [
    "marker_map_supervised_markers = {}\n",
    "marker_map_supervised_f1 = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QAKwVs5SaYUa"
   },
   "outputs": [],
   "source": [
    "for k in k_range:\n",
    "    train_indices, val_indices, test_indices = np.load(model_save_path + 'experiment_data_folds/marker_map_supervised_indices_k_{}.npy'.format(k), allow_pickle = True)\n",
    "    misclass_rate, test_rep, cm = np.load(model_save_path + 'marker_map_supervised_results_k_{}.npy'.format(k), allow_pickle=True)\n",
    "    weighted_f1_score = test_rep['weighted avg']['f1-score']\n",
    "    markers = np.load(model_save_path + 'marker_map_supervised_markers_k_{}.npy'.format(k), allow_pickle = True)\n",
    "    marker_data = np.zeros(X.shape[1])\n",
    "    marker_data[markers] = 1\n",
    "    marker_map_supervised_markers[k] = marker_data\n",
    "    marker_map_supervised_f1[k] = weighted_f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0W_-Xl2Z3Ij4"
   },
   "source": [
    "### MarkerMap Mixed Supervision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9EOdEyWS3IQ_"
   },
   "outputs": [],
   "source": [
    "marker_map_mixed_markers = {}\n",
    "marker_map_mixed_f1 = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fNf59NwW3NY7"
   },
   "outputs": [],
   "source": [
    "for k in k_range:\n",
    "    train_indices, val_indices, test_indices = np.load(model_save_path + 'experiment_data_folds/marker_map_mixed_indices_k_{}.npy'.format(k), allow_pickle = True)\n",
    "    misclass_rate, test_rep, cm = np.load(model_save_path + 'marker_map_mixed_results_k_{}.npy'.format(k), allow_pickle=True)\n",
    "    weighted_f1_score = test_rep['weighted avg']['f1-score']\n",
    "    markers = np.load(model_save_path + 'marker_map_mixed_markers_k_{}.npy'.format(k), allow_pickle = True)\n",
    "    marker_data = np.zeros(X.shape[1])\n",
    "    marker_data[markers] = 1\n",
    "    marker_map_mixed_markers[k] = marker_data\n",
    "    marker_map_mixed_f1[k] = weighted_f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_9Bia_jhaO7q"
   },
   "source": [
    "### Concrete VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ym-HhrgNaQ1D"
   },
   "outputs": [],
   "source": [
    "concrete_vae_markers = {}\n",
    "concrete_vae_f1 = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7HMta8dZbVlY"
   },
   "outputs": [],
   "source": [
    "for k in k_range:\n",
    "    train_indices, val_indices, test_indices = np.load(model_save_path + 'experiment_data_folds/concrete_vae_indices_k_{}.npy'.format(k), allow_pickle = True)\n",
    "    misclass_rate, test_rep, cm = np.load(model_save_path + 'concrete_vae_results_k_{}.npy'.format(k), allow_pickle=True)\n",
    "    weighted_f1_score = test_rep['weighted avg']['f1-score']\n",
    "    markers = np.load(model_save_path + 'concrete_vae_markers_k_{}.npy'.format(k), allow_pickle = True)\n",
    "    marker_data = np.zeros(X.shape[1])\n",
    "    marker_data[markers] = 1\n",
    "    concrete_vae_markers[k] = marker_data\n",
    "    concrete_vae_f1[k] = weighted_f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5584Ak6jPOFA"
   },
   "source": [
    "## LassoNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oNVlVN-mPPMe"
   },
   "outputs": [],
   "source": [
    "lasso_net_markers = {}\n",
    "lasso_net_f1 = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2HnRAfhzPS9u"
   },
   "outputs": [],
   "source": [
    "for k in k_range:\n",
    "    train_indices, val_indices, test_indices = np.load(model_save_path + 'experiment_data_folds/lasso_net_indices_k_{}.npy'.format(k), allow_pickle = True)\n",
    "    misclass_rate, test_rep, cm = np.load(model_save_path + 'lasso_net_results_k_{}.npy'.format(k), allow_pickle=True)\n",
    "    weighted_f1_score = test_rep['weighted avg']['f1-score']\n",
    "    markers = np.load(model_save_path + 'lasso_net_markers_k_{}.npy'.format(k), allow_pickle = True)\n",
    "    marker_data = np.zeros(X.shape[1])\n",
    "    marker_data[markers] = 1\n",
    "    lasso_net_markers[k] = marker_data\n",
    "    lasso_net_f1[k] = weighted_f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oloWkNm2aRVr"
   },
   "source": [
    "### The Actual Subplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "07_wUyaYkblI"
   },
   "outputs": [],
   "source": [
    "def plot_row(ax, name, k_range, markers, f1):\n",
    "    assert len(ax) == len(k_range)\n",
    "    for i in range(len(k_range)):\n",
    "        col = ax[i]\n",
    "        k = k_range[i]\n",
    "        if i == 0:\n",
    "            col.set_ylabel(\"{}\".format(name))\n",
    "        col.set_ylim([0, 1.2])\n",
    "        col.set_yticks([0, 1.0])\n",
    "        col.set_title(\"{} Markers(Weighted F1 {:.3g})\".format(k, f1[k]))        \n",
    "        col.bar(range(X.shape[1]), markers[k], width = 10)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D_0-PvwZbhVw"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=10, ncols = len(k_range), figsize = (20, 15))\n",
    "\n",
    "plot_row(axs[0], 'Smash RF', k_range, smash_rf_markers, smash_rf_f1)\n",
    "plot_row(axs[1], 'Smash DNN', k_range, smash_dnn_markers, smash_dnn_f1)\n",
    "plot_row(axs[2], 'RankCorr', k_range, rankcorr_markers, rankcorr_f1)\n",
    "plot_row(axs[3], 'L1 VAE', k_range, l1_vae_markers, l1_vae_f1)\n",
    "plot_row(axs[4], 'GlobalGate VAE', k_range, globalgate_vae_markers, globalgate_vae_f1)\n",
    "plot_row(axs[5], 'MarkerMap Unsupervised', k_range, marker_map_unsupervised_markers, marker_map_unsupervised_f1)\n",
    "plot_row(axs[6], 'MarkerMap Supervised', k_range, marker_map_supervised_markers, marker_map_supervised_f1)\n",
    "plot_row(axs[7], 'MarkerMap Mixed Supervision', k_range, marker_map_mixed_markers, marker_map_mixed_f1)\n",
    "plot_row(axs[8], 'ConcreteVAE', k_range, concrete_vae_markers, concrete_vae_f1)\n",
    "plot_row(axs[9], 'LassoNet', k_range, lasso_net_markers, lasso_net_f1)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(viz_save_path + 'CiteSeq_SelectedMarkers_All_Methods_ks.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pchyVj1CyWOj"
   },
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qw_O6WnV_12L"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OyCVSHW6_2Zr"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CITE-seq.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
