{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kuKoVgDwzrgo"
   },
   "source": [
    "# All the Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZgkcUm9Pzn7_",
    "outputId": "e097abfd-af90-46c4-c7a0-882395c9fdbb"
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "import itertools \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from lassonet import LassoNetClassifier\n",
    "\n",
    "\n",
    "from RankCorr.picturedRocks import Rocks\n",
    "import smashpy as smashpy\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from markermap.utils import MarkerMap, ConcreteVAE_NMSL, VAE_Gumbel_GlobalGate, VAE_l1_diag\n",
    "from markermap.utils import (\n",
    "    model_variances,\n",
    "    new_model_metrics, \n",
    "    plot_confusion_matrix,\n",
    "    split_data_into_dataloaders, \n",
    "    train_save_model,\n",
    "    visualize_save_embedding, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger(\"lightning\").setLevel(logging.ERROR)\n",
    "pl_loggers = [ logging.getLogger(name) for name in logging.root.manager.loggerDict if 'lightning' in name ]\n",
    "\n",
    "for logger in pl_loggers:\n",
    "    logger.setLevel(logging.ERROR)\n",
    "    \n",
    "np.warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zli798tc3I1E"
   },
   "source": [
    "# These should be parameters later on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dyZgQa5V3Ird"
   },
   "outputs": [],
   "source": [
    "z_size = 16\n",
    "hidden_layer_size = 256\n",
    "\n",
    "# really good results for vanilla VAE on synthetic data with EPOCHS set to 50, \n",
    "# but when running locally set to 10 for reasonable run times\n",
    "batch_size = 64\n",
    "batch_norm = True\n",
    "\n",
    "\n",
    "global_t = 3.0\n",
    "\n",
    "# k_range = [10,25,50,100,250]\n",
    "k_range = [10]\n",
    "k = 50\n",
    "num_times = 1\n",
    "\n",
    "#pytorch lightning stuff\n",
    "gpus = 0\n",
    "tpu_cores = None\n",
    "precision=32\n",
    "\n",
    "# The smashpy methods set global seeds that mess with sampling. These seeds are used \n",
    "# to stop those methods from using the same global seed over and over.\n",
    "possible_seeds = np.random.randint(low=1, high = 1000000, size = 400)\n",
    "seed_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z3YA3apjf8hc"
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "num_cores = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zNL5KfNXyX_w"
   },
   "source": [
    "# Here goes all the stuff that we change from dataset to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VH7bxl6U3CUC"
   },
   "outputs": [],
   "source": [
    "from os import path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2BQ8JwQoyXhv"
   },
   "outputs": [],
   "source": [
    "dataset_dir = '../data/zeisel/'\n",
    "model_save_path = '../data/zeisel/models/'\n",
    "viz_save_path = '../data/zeisel/visualizations/'\n",
    "\n",
    "if not path.exists(model_save_path):\n",
    "  os.makedirs(model_save_path)\n",
    "\n",
    "if not path.exists(model_save_path + 'experiment_data_folds/'):\n",
    "  os.makedirs(model_save_path + 'experiment_data_folds/')\n",
    "  \n",
    "if not path.exists(viz_save_path):\n",
    "  os.makedirs(viz_save_path)\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xv2eoOiMyg3v"
   },
   "source": [
    "# Dataset Specific Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sa6gNnbY-cnt"
   },
   "source": [
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ovIGptmfJpEh"
   },
   "outputs": [],
   "source": [
    "adata = sc.read_h5ad(dataset_dir + \"Zeisel.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "uuifK9yxGZRn",
    "outputId": "3f4925ce-ffc4-4906-d463-1cabbd3a331e"
   },
   "outputs": [],
   "source": [
    "adata.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h9b6AtC4GlWu",
    "outputId": "3a76bb0a-52c1-4179-c57a-e76fd7ad52a2"
   },
   "outputs": [],
   "source": [
    "adata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uQm9Q1GyouO3",
    "outputId": "d6e165a4-ab53-478a-9b09-854435b39ce7"
   },
   "outputs": [],
   "source": [
    "np.apply_along_axis(np.mean, 0, adata.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KJaPYIx-pCAU",
    "outputId": "828729d7-68d6-4e55-e71b-1781de5a5cf3"
   },
   "outputs": [],
   "source": [
    "np.apply_along_axis(np.var, 0, adata.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VMroe1buSQOp"
   },
   "outputs": [],
   "source": [
    "X = adata.X.copy()\n",
    "adata.obs['names']=adata.obs['names0']\n",
    "adata.obs['annotation'] = adata.obs['names0']\n",
    "labels = adata.obs['names0'].values\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(labels)\n",
    "y = encoder.transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MmNfRwkAS0JC",
    "outputId": "80c89c4d-3000-4cf3-d4f8-8bca28740870"
   },
   "outputs": [],
   "source": [
    "input_size = X.shape[1]\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CpqrOe55ymwy"
   },
   "source": [
    "# Set Up Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J6NwRjlfeepy"
   },
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "3VnyFaA1ehCm",
    "outputId": "507c46dc-95c0-4265-c6b4-12d7d2fd744d"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for tryy in range(1,num_times+1):\n",
    "    _, _, _, train_indices, val_indices, test_indices = split_data_into_dataloaders(X, y, 0.7, 0.1)\n",
    "    all_markers = np.arange(X.shape[1])\n",
    "    X_train = X[np.concatenate([train_indices, val_indices]), :]\n",
    "    y_train = y[np.concatenate([train_indices, val_indices])]\n",
    "    X_test = X[test_indices,:]\n",
    "    y_test = y[test_indices]\n",
    "    results = new_model_metrics(X_train, y_train, X_test, y_test, markers = all_markers)\n",
    "    np.save(model_save_path + 'all_markers_results_{}.npy'.format(tryy), results)\n",
    "    np.save(model_save_path + 'all_markers_{}.npy'.format(tryy), all_markers)\n",
    "    np.save(model_save_path + 'experiment_data_folds/all_markers_indices_{}.npy'.format(tryy), (train_indices, val_indices, test_indices))\n",
    "\n",
    "    visualize_save_embedding(X, y, encoder, 'All Marker Visualization', path = viz_save_path + 'all_markers_{}.pdf'.format(tryy), markers = all_markers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DaU3wodPT7mV"
   },
   "source": [
    "## Train Smash Random Forest\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cJuMQIxtXl-r"
   },
   "outputs": [],
   "source": [
    "# needed for random forest Smash\n",
    "!mkdir Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3xX1y8POT-ob"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for tryy in range(1,num_times+1):\n",
    "    # The smashpy methods set global seeds that mess with sampling. These seeds are used \n",
    "    # to stop those methods from using the same global seed over and over.\n",
    "    np.random.seed(possible_seeds[seed_index])\n",
    "    seed_index += 1\n",
    "    _, _, _, train_indices, val_indices, test_indices = split_data_into_dataloaders(X, y, 0.7, 0.1)\n",
    "    train_X_y = adata[np.concatenate([train_indices, val_indices]), :]\n",
    "    sm = smashpy.smashpy()\n",
    "    clf = sm.ensemble_learning(train_X_y, group_by=\"annotation\", classifier=\"RandomForest\", balance=True, verbose=True)\n",
    "    selectedGenes, selectedGenes_dict = sm.gini_importance(train_X_y, clf, group_by=\"annotation\", verbose=True, restrict_top=(\"global\", k))\n",
    "    # since this selects k per class, need select randomly from each classes\n",
    "    smash_markers = adata.var.index.get_indexer(selectedGenes)\n",
    "\n",
    "    X_train = X[np.concatenate([train_indices, val_indices]), :]\n",
    "    y_train = y[np.concatenate([train_indices, val_indices])]\n",
    "    X_test = X[test_indices,:]\n",
    "    y_test = y[test_indices]\n",
    "    results = new_model_metrics(X_train, y_train, X_test, y_test, markers = smash_markers)\n",
    "    np.save(model_save_path + 'smash_rf_results_{}.npy'.format(tryy), results)\n",
    "    np.save(model_save_path + 'smash_rf_markers_{}.npy'.format(tryy), smash_markers)\n",
    "    np.save(model_save_path + 'experiment_data_folds/smash_rf_indices_{}.npy'.format(tryy), (train_indices, val_indices, test_indices))\n",
    "\n",
    "    visualize_save_embedding(X, y, encoder, 'Smash Random Forest Marker Visualization', path = viz_save_path + 'smash_rf_markers_{}.png'.format(tryy), markers = smash_markers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "36K-CYMpTuw2"
   },
   "source": [
    "## Train Smash DNN\n",
    "\n",
    "the data is treated a bit differently than our other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dihae7ssynzJ"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for tryy in range(1,num_times+1):\n",
    "    # The smashpy methods set global seeds that mess with sampling. These seeds are used \n",
    "    # to stop those methods from using the same global seed over and over.\n",
    "    np.random.seed(possible_seeds[seed_index])\n",
    "    seed_index += 1\n",
    "    _, _, _, train_indices, val_indices, test_indices = split_data_into_dataloaders(X, y, 0.7, 0.1)\n",
    "    train_X_y = adata[np.concatenate([train_indices, val_indices]), :]\n",
    "    sm = smashpy.smashpy()\n",
    "    sm.DNN(train_X_y, group_by=\"annotation\", model=None, balance=True, verbose=True, save=False)\n",
    "    selectedGenes, selectedGenes_dict = sm.run_shap(train_X_y, group_by=\"annotation\", model=None, verbose=True, pct=0.1, restrict_top=(\"global\", k))\n",
    "    # since this selects k per class, need select randomly from each classes\n",
    "    smash_markers = adata.var.index.get_indexer(selectedGenes)\n",
    "\n",
    "    X_train = X[np.concatenate([train_indices, val_indices]), :]\n",
    "    y_train = y[np.concatenate([train_indices, val_indices])]\n",
    "    X_test = X[test_indices,:]\n",
    "    y_test = y[test_indices]\n",
    "    results = new_model_metrics(X_train, y_train, X_test, y_test, markers = smash_markers)\n",
    "    np.save(model_save_path + 'smash_results_{}.npy'.format(tryy), results)\n",
    "    np.save(model_save_path + 'smash_markers_{}.npy'.format(tryy), smash_markers)\n",
    "    np.save(model_save_path + 'experiment_data_folds/smash_indices_{}.npy'.format(tryy), (train_indices, val_indices, test_indices))\n",
    "\n",
    "    visualize_save_embedding(X, y, encoder, 'Smash Marker Visualization', path = viz_save_path + 'smash_markers_{}.png'.format(tryy), markers = smash_markers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The smashpy methods set global seeds that mess with sampling. These seeds are used \n",
    "# to stop those methods from using the same global seed over and over.\n",
    "np.random.seed(possible_seeds[seed_index])\n",
    "seed_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L9kicuw3OKgq"
   },
   "source": [
    "## Train RankCorr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MfzfhotGKNxo"
   },
   "outputs": [],
   "source": [
    "for tryy in range(1,num_times+1):\n",
    "    _, _, _, train_indices, val_indices, test_indices = split_data_into_dataloaders(X, y, 0.7, 0.1)\n",
    "    X_train = X[np.concatenate([train_indices, val_indices]), :]\n",
    "    y_train = y[np.concatenate([train_indices, val_indices])]\n",
    "    X_test = X[test_indices,:]\n",
    "    y_test = y[test_indices]\n",
    "\n",
    "    data = Rocks(X_train, y_train)\n",
    "    lamb = 4.7# this can be whatever\n",
    "\n",
    "    rankcorr_markers = data.CSrankMarkers(lamb=lamb, writeOut=False, keepZeros=False, onlyNonZero=False)\n",
    "    if len(rankcorr_markers) < k:\n",
    "        raise Exception(\"Increase lamb for rank corr procedure\")\n",
    "    if len(rankcorr_markers) > k:\n",
    "        rankcorr_markers = rankcorr_markers[:k]\n",
    "    geneNames = np.array(adata.var.index)\n",
    "    data.genes = geneNames\n",
    "    marker_genes = data.markers_to_genes(rankcorr_markers)\n",
    "    \n",
    "\n",
    "    results = new_model_metrics(X_train, y_train, X_test, y_test, markers = rankcorr_markers)\n",
    "    np.save(model_save_path + 'rankcorr_results_{}.npy'.format(tryy), results)\n",
    "    np.save(model_save_path + 'rankcorr_markers_{}.npy'.format(tryy), rankcorr_markers)\n",
    "    np.save(model_save_path + 'experiment_data_folds/rankcorr_indices_{}.npy'.format(tryy), (train_indices, val_indices, test_indices))\n",
    "\n",
    "    visualize_save_embedding(X, y, encoder, 'RankCorr Marker Visualization', path = viz_save_path + 'rankcorr_markers_{}.png'.format(tryy), markers = rankcorr_markers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4UT0YG-m9CxL"
   },
   "source": [
    "## Train L1 VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wcTlqJiJ9CgS"
   },
   "outputs": [],
   "source": [
    "feature_std = torch.tensor(X).std(dim = 0)\n",
    "for tryy in range(1,num_times+1):\n",
    "    train_dataloader, val_dataloader, _, train_indices, val_indices, test_indices = split_data_into_dataloaders(X, y, 0.7, 0.1, num_workers = num_cores, batch_size = batch_size)\n",
    "    X_train = X[np.concatenate([train_indices, val_indices]), :]\n",
    "    y_train = y[np.concatenate([train_indices, val_indices])]\n",
    "    X_test = X[test_indices,:]\n",
    "    y_test = y[test_indices]\n",
    "\n",
    "    model = VAE_l1_diag(input_size, hidden_layer_size, z_size, batch_norm = batch_norm)\n",
    "    tmp_path = model_save_path + 'l1_vae_{}.ckpt'.format(tryy)\n",
    "    # DO NOT USE IN OTHER WORKLOADS\n",
    "    train_save_model(model, train_dataloader, val_dataloader, tmp_path, gpus=gpus, tpu_cores = tpu_cores, min_epochs = 25, \n",
    "                     max_epochs = 100, auto_lr = True, early_stopping_patience = 4, precision = precision)\n",
    "    l1_markers = model.markers(feature_std = feature_std.to(model.device), k = k).clone().cpu().detach().numpy()\n",
    "    \n",
    "\n",
    "    results = new_model_metrics(X_train, y_train, X_test, y_test, markers = l1_markers)\n",
    "    np.save(model_save_path + 'l1_vae_results_{}.npy'.format(tryy), results)\n",
    "    np.save(model_save_path + 'l1_vae_markers_{}.npy'.format(tryy), l1_markers)\n",
    "    np.save(model_save_path + 'experiment_data_folds/l1_vae_indices_{}.npy'.format(tryy), (train_indices, val_indices, test_indices))\n",
    "\n",
    "    visualize_save_embedding(X, y, encoder, 'L1 VAE Marker Visualization', path = viz_save_path + 'l1_vae_markers_{}.png'.format(tryy), markers = l1_markers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NTLLf99HA1o6"
   },
   "source": [
    "## Train Global Gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G3gYOblwA0r5"
   },
   "outputs": [],
   "source": [
    "for tryy in range(1,num_times+1):\n",
    "    train_dataloader, val_dataloader, _, train_indices, val_indices, test_indices = split_data_into_dataloaders(X, y, 0.7, 0.1, num_workers=num_cores, batch_size = batch_size)\n",
    "    X_train = X[np.concatenate([train_indices, val_indices]), :]\n",
    "    y_train = y[np.concatenate([train_indices, val_indices])]\n",
    "    X_test = X[test_indices,:]\n",
    "    y_test = y[test_indices]\n",
    "\n",
    "    model = VAE_Gumbel_GlobalGate(input_size, hidden_layer_size, z_size, k = k, t = global_t, bias = True, temperature_decay=0.95, batch_norm = batch_norm)\n",
    "    tmp_path = model_save_path + 'globalgate_vae_{}.ckpt'.format(tryy)\n",
    "    # DO NOT USE IN OTHER WORKLOADS\n",
    "    train_save_model(model, train_dataloader, val_dataloader, tmp_path, gpus = gpus, tpu_cores = tpu_cores, \n",
    "                     min_epochs = 25, max_epochs = 100, auto_lr = True, max_lr = 0.00001, early_stopping_patience =  10, \n",
    "                     lr_explore_mode = 'linear', num_lr_rates = 500, precision = precision)\n",
    "    globalgate_markers = model.markers().clone().cpu().detach().numpy()\n",
    "    \n",
    " \n",
    "    results = new_model_metrics(X_train, y_train, X_test, y_test, markers = globalgate_markers)\n",
    "    np.save(model_save_path + 'globalgate_vae_results_{}.npy'.format(tryy), results)\n",
    "    np.save(model_save_path + 'globalgate_vae_markers_{}.npy'.format(tryy), globalgate_markers)\n",
    "    np.save(model_save_path + 'experiment_data_folds/globalgate_vae_indices_{}.npy'.format(tryy), (train_indices, val_indices, test_indices))\n",
    "\n",
    "    visualize_save_embedding(X, y, encoder, 'Global Gate VAE Marker Visualization', path = viz_save_path + 'globalgate_vae_markers_{}.png'.format(tryy), markers = globalgate_markers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Kh0fu77RlWp"
   },
   "source": [
    "## Train MarkerMap Unsupervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I9BoR6M-Rnfm"
   },
   "outputs": [],
   "source": [
    "for tryy in range(1,num_times+1):\n",
    "    train_dataloader, val_dataloader, _, train_indices, val_indices, test_indices = split_data_into_dataloaders(X, y, 0.7, 0.1, num_workers = num_cores, batch_size = batch_size)\n",
    "    X_train = X[np.concatenate([train_indices, val_indices]), :]\n",
    "    y_train = y[np.concatenate([train_indices, val_indices])]\n",
    "    X_test = X[test_indices,:]\n",
    "    y_test = y[test_indices]\n",
    "    model = MarkerMap(input_size, hidden_layer_size, z_size, k = k, t = global_t, bias = True, temperature_decay=0.95, alpha = 0.95, batch_norm = batch_norm, loss_tradeoff = 1.0, num_classes = None)\n",
    "    tmp_path = model_save_path + 'marker_map_unsupervised_{}.ckpt'.format(tryy)\n",
    "    # DO NOT USE IN OTHER WORKLOADS\n",
    "    train_save_model(model, train_dataloader, val_dataloader, tmp_path, gpus=gpus, min_epochs = 25, max_epochs = 100, auto_lr = True, max_lr = 0.0001, early_stopping_patience = 4, \n",
    "                     lr_explore_mode = 'linear', num_lr_rates = 500, precision = precision)\n",
    "    unsupervised_markers = model.markers().clone().cpu().detach().numpy()\n",
    "    \n",
    "\n",
    "    results = new_model_metrics(X_train, y_train, X_test, y_test, markers = unsupervised_markers)\n",
    "    np.save(model_save_path + 'marker_map_unsupervised_results_{}.npy'.format(tryy), results)\n",
    "    np.save(model_save_path + 'marker_map_unsupervised_markers_{}.npy'.format(tryy), unsupervised_markers)\n",
    "    np.save(model_save_path + 'experiment_data_folds/marker_map_unsupervised_indices_{}.npy'.format(tryy), (train_indices, val_indices, test_indices))\n",
    "\n",
    "    visualize_save_embedding(X, y, encoder, 'Marker Map Unsupervised Marker Visualization', path = viz_save_path + 'marker_map_unsupervised_markers_{}.png'.format(tryy), markers = unsupervised_markers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train MarkerMap Supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tryy in range(1,num_times+1):\n",
    "    train_dataloader, val_dataloader, _, train_indices, val_indices, test_indices = split_data_into_dataloaders(X, y, 0.7, 0.1, num_workers = num_cores, batch_size = batch_size)\n",
    "    X_train = X[np.concatenate([train_indices, val_indices]), :]\n",
    "    y_train = y[np.concatenate([train_indices, val_indices])]\n",
    "    X_test = X[test_indices,:]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    model = MarkerMap(input_size, hidden_layer_size, z_size, num_classes = len(encoder.classes_), \n",
    "                             k = k, t = global_t, bias = True, temperature_decay=0.95, alpha = 0.95, batch_norm = batch_norm, loss_tradeoff = 0)\n",
    "    tmp_path = model_save_path + 'marker_map_supervised_{}.ckpt'.format(tryy)\n",
    "    # DO NOT USE IN OTHER WORKLOADS\n",
    "    train_save_model(model, train_dataloader, val_dataloader, tmp_path, gpus=gpus, tpu_cores = tpu_cores, \n",
    "                     min_epochs = 25, max_epochs = 100, auto_lr = True, early_stopping_patience = 3, precision = precision, lr_explore_mode = 'linear', num_lr_rates=500)\n",
    "    markers = model.markers().clone().cpu().detach().numpy()\n",
    "    \n",
    "\n",
    "    results = new_model_metrics(X_train, y_train, X_test, y_test, markers = markers)\n",
    "    np.save(model_save_path + 'marker_map_supervised_results_{}.npy'.format(tryy), results)\n",
    "    np.save(model_save_path + 'marker_map_supervised_markers_{}.npy'.format(tryy), markers)\n",
    "    np.save(model_save_path + 'experiment_data_folds/marker_map_supervised_indices_{}.npy'.format(tryy), (train_indices, val_indices, test_indices))\n",
    "\n",
    "    visualize_save_embedding(X, y, encoder, 'MarkerMap Supervised Marker Visualization', path = viz_save_path + 'marker_map_supervised_markers_{}.png'.format(tryy), markers = markers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z0dnAPMhlaC3"
   },
   "source": [
    "## MakerMap Mixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G4QbqLqbldFo"
   },
   "outputs": [],
   "source": [
    "for tryy in range(1,num_times+1):\n",
    "    train_dataloader, val_dataloader, _, train_indices, val_indices, test_indices = split_data_into_dataloaders(X, y, 0.7, 0.1, num_workers = num_cores, batch_size = batch_size)\n",
    "    X_train = X[np.concatenate([train_indices, val_indices]), :]\n",
    "    y_train = y[np.concatenate([train_indices, val_indices])]\n",
    "    X_test = X[test_indices,:]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    model = MarkerMap(input_size, hidden_layer_size, z_size, num_classes = len(encoder.classes_), \n",
    "                             k = k, t = global_t, bias = True, temperature_decay=0.95, alpha = 0.95, batch_norm = batch_norm, loss_tradeoff = 0.5)\n",
    "    tmp_path = model_save_path + 'marker_map_mixed_{}.ckpt'.format(tryy)\n",
    "    # DO NOT USE IN OTHER WORKLOADS\n",
    "    train_save_model(model, train_dataloader, val_dataloader, tmp_path, gpus=gpus, tpu_cores = tpu_cores, \n",
    "                     min_epochs = 25, max_epochs = 100, auto_lr = True, early_stopping_patience = 3, precision = precision, lr_explore_mode = 'linear', num_lr_rates=500)\n",
    "    markers = model.markers().clone().cpu().detach().numpy()\n",
    "    \n",
    "\n",
    "    results = new_model_metrics(X_train, y_train, X_test, y_test, markers = markers)\n",
    "    np.save(model_save_path + 'marker_map_mixed_results_{}.npy'.format(tryy), results)\n",
    "    np.save(model_save_path + 'marker_map_mixed_markers_{}.npy'.format(tryy), markers)\n",
    "    np.save(model_save_path + 'experiment_data_folds/marker_map_mixed_indices_{}.npy'.format(tryy), (train_indices, val_indices, test_indices))\n",
    "\n",
    "    visualize_save_embedding(X, y, encoder, 'MarkerMap Mixed Supervision Marker Visualization', path = viz_save_path + 'marker_map_mixed_markers_{}.png'.format(tryy), markers = markers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z_uAjoDSde-v"
   },
   "source": [
    "## Concrete VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eqbs1Ni8ypMY"
   },
   "outputs": [],
   "source": [
    "for tryy in range(1,num_times+1):\n",
    "    train_dataloader, val_dataloader, _, train_indices, val_indices, test_indices = split_data_into_dataloaders(X, y, 0.7, 0.1, num_workers = num_cores, batch_size = batch_size)\n",
    "    X_train = X[np.concatenate([train_indices, val_indices]), :]\n",
    "    y_train = y[np.concatenate([train_indices, val_indices])]\n",
    "    X_test = X[test_indices,:]\n",
    "    y_test = y[test_indices]\n",
    "\n",
    "    model = ConcreteVAE_NMSL(input_size, hidden_layer_size, z_size, k = k, t = global_t, bias = True, temperature_decay = 0.9, batch_norm = batch_norm)\n",
    "    tmp_path = model_save_path + 'concrete_vae_{}.ckpt'.format(tryy)\n",
    "    train_save_model(model, train_dataloader, val_dataloader, tmp_path, gpus=1, min_epochs = 25, max_epochs = 100, auto_lr = True, max_lr = 0.0001, early_stopping_patience = 3, \n",
    "                     lr_explore_mode = 'linear', num_lr_rates = 500, precision = precision)\n",
    "    concrete_vae_markers = model.markers().clone().cpu().detach().numpy()\n",
    "    \n",
    "\n",
    "    results = new_model_metrics(X_train, y_train, X_test, y_test, markers = concrete_vae_markers)\n",
    "    np.save(model_save_path + 'concrete_vae_results_{}.npy'.format(tryy), results)\n",
    "    np.save(model_save_path + 'concrete_vae_markers_{}.npy'.format(tryy), concrete_vae_markers)\n",
    "    np.save(model_save_path + 'experiment_data_folds/concrete_vae_indices_{}.npy'.format(tryy), (train_indices, val_indices, test_indices))\n",
    "\n",
    "    visualize_save_embedding(X, y, encoder, 'Concrete VAE Marker Visualization', path = viz_save_path + 'concrete_vae_markers_{}.png'.format(tryy), markers = concrete_vae_markers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1tLcr7pD97JR"
   },
   "source": [
    "## LassoNet\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wpP9WuQwOtQY"
   },
   "outputs": [],
   "source": [
    "dev = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WVRtQbblWyuk"
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from lassonet import plot_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B_1yX-Lt-L1M"
   },
   "outputs": [],
   "source": [
    "for tryy in range(1,num_times+1):  \n",
    "    _, _, _, train_indices, val_indices, test_indices = split_data_into_dataloaders(X, y, 0.7, 0.1)\n",
    "    X_train = X[train_indices, :]\n",
    "    y_train = y[train_indices]\n",
    "    X_val = X[val_indices,:]\n",
    "    y_val = y[val_indices]\n",
    "    X_test = X[test_indices,:]\n",
    "    y_test = y[test_indices]\n",
    "    model = LassoNetClassifier()\n",
    "    model.path(X_train, y_train, X_val = X_val, y_val = y_val)\n",
    "    lasso_net_markers = torch.argsort(model.feature_importances_, descending = True).cpu().numpy()[:k]\n",
    "    results = new_model_metrics(X_train, y_train, X_test, y_test, markers = lasso_net_markers)\n",
    "    np.save(model_save_path + 'lasso_net_results_{}.npy'.format(tryy), results)\n",
    "    np.save(model_save_path + 'lasso_net_markers_{}.npy'.format(tryy), lasso_net_markers)\n",
    "    np.save(model_save_path + 'experiment_data_folds/lasso_net_indices_{}.npy'.format(tryy), (train_indices, val_indices, test_indices))\n",
    "\n",
    "    visualize_save_embedding(X, y, encoder, 'LassoNet Marker Visualization', path = viz_save_path + 'lasso_net_markers_{}.png'.format(tryy), markers = lasso_net_markers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xSv5uYd5sH0h"
   },
   "source": [
    "## Get Model Metrics from KNNs Classifiers\n",
    "\n",
    "The above just generates metrics for the Random Forests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x2UkZ50PvhWx"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K6Gu-El7vlPG"
   },
   "outputs": [],
   "source": [
    "def generate_metrics_from_saved_files(X, y, folds_path, markers_path, classifier_model, save_path):\n",
    "    train_indices, val_indices, test_indices = np.load(folds_path, allow_pickle = True)\n",
    "    markers = np.load(markers_path, allow_pickle = True)\n",
    "    X_train = X[np.concatenate([train_indices, val_indices]), :]\n",
    "    y_train = y[np.concatenate([train_indices, val_indices])]\n",
    "    X_test = X[test_indices, :]\n",
    "    y_test = y[test_indices]\n",
    "    results = new_model_metrics(X_train, y_train, X_test, y_test, markers = markers, model = classifier_model)\n",
    "\n",
    "    np.save(save_path, results)\n",
    "    return\n",
    "\n",
    "def batch_generate_metrics_from_saved_files(X, y, format_folds_path, format_markers_path, format_save_path):\n",
    "    for tryy in range(1, num_times+1):\n",
    "        classifier_model = KNeighborsClassifier()\n",
    "        generate_metrics_from_saved_files(X, y, format_folds_path.format(tryy), format_markers_path.format(tryy), classifier_model, format_save_path.format(tryy))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8C_Mz9SGfpw1",
    "outputId": "5f79aee6-7214-4095-cd12-98f6dd29e728"
   },
   "outputs": [],
   "source": [
    "batch_generate_metrics_from_saved_files(X, y,\n",
    "                                  model_save_path+'experiment_data_folds/all_markers_indices_{}.npy',\n",
    "                                  model_save_path+'all_markers_{}.npy',\n",
    "                                  model_save_path+'all_markers_knn_results_{}.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qSOCJ2r9vryq"
   },
   "outputs": [],
   "source": [
    "batch_generate_metrics_from_saved_files(X, y,\n",
    "                                  model_save_path+'experiment_data_folds/l1_vae_indices_{}.npy',\n",
    "                                  model_save_path+'l1_vae_markers_{}.npy',\n",
    "                                  model_save_path+'l1_vae_knn_results_{}.npy')\n",
    "\n",
    "batch_generate_metrics_from_saved_files(X, y,\n",
    "                                  model_save_path+'experiment_data_folds/smash_rf_indices_{}.npy',\n",
    "                                  model_save_path+'smash_rf_markers_{}.npy',\n",
    "                                  model_save_path+'smash_rf_knn_results_{}.npy')\n",
    "\n",
    "batch_generate_metrics_from_saved_files(X, y,\n",
    "                                  model_save_path+'experiment_data_folds/smash_indices_{}.npy',\n",
    "                                  model_save_path+'smash_markers_{}.npy',\n",
    "                                  model_save_path+'smash_knn_results_{}.npy')\n",
    "\n",
    "batch_generate_metrics_from_saved_files(X, y,\n",
    "                                  model_save_path+'experiment_data_folds/rankcorr_indices_{}.npy',\n",
    "                                  model_save_path+'rankcorr_markers_{}.npy',\n",
    "                                  model_save_path+'rankcorr_knn_results_{}.npy')\n",
    "\n",
    "batch_generate_metrics_from_saved_files(X, y,\n",
    "                                  model_save_path+'experiment_data_folds/globalgate_vae_indices_{}.npy',\n",
    "                                  model_save_path+'globalgate_vae_markers_{}.npy',\n",
    "                                  model_save_path+'globalgate_vae_knn_results_{}.npy')\n",
    "\n",
    "batch_generate_metrics_from_saved_files(X, y,\n",
    "                                  model_save_path+'experiment_data_folds/marker_map_unsupervised_indices_{}.npy',\n",
    "                                  model_save_path+'marker_map_unsupervised_markers_{}.npy',\n",
    "                                  model_save_path+'marker_map_unsupervised_knn_results_{}.npy')\n",
    "\n",
    "\n",
    "batch_generate_metrics_from_saved_files(X, y,\n",
    "                                  model_save_path+'experiment_data_folds/marker_map_supervised_indices_{}.npy',\n",
    "                                  model_save_path+'marker_map_supervised_markers_{}.npy',\n",
    "                                  model_save_path+'marker_map_supervised_knn_results_{}.npy')\n",
    "\n",
    "\n",
    "batch_generate_metrics_from_saved_files(X, y,\n",
    "                                  model_save_path+'experiment_data_folds/concrete_vae_indices_{}.npy',\n",
    "                                  model_save_path+'concrete_vae_markers_{}.npy',\n",
    "                                  model_save_path+'concrete_vae_knn_results_{}.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gRtLWsNiqazo"
   },
   "outputs": [],
   "source": [
    "batch_generate_metrics_from_saved_files(X, y,\n",
    "                                  model_save_path+'experiment_data_folds/marker_map_mixed_indices_{}.npy',\n",
    "                                  model_save_path+'marker_map_mixed_markers_{}.npy',\n",
    "                                  model_save_path+'marker_map_mixed_knn_results_{}.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8kkwacuToH0K"
   },
   "outputs": [],
   "source": [
    "batch_generate_metrics_from_saved_files(X, y,\n",
    "                                  model_save_path+'experiment_data_folds/lasso_net_indices_{}.npy',\n",
    "                                  model_save_path+'lasso_net_markers_{}.npy',\n",
    "                                  model_save_path+'lasso_net_knn_results_{}.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ac3v6MHk6Ag_"
   },
   "source": [
    "# Results and Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r49opYsbRZm0"
   },
   "source": [
    "## Accuracies and F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "onT-MVmoGfKO"
   },
   "outputs": [],
   "source": [
    "result_axis = [\n",
    " ('All Markers', 'all_markers_results_{}.npy', 'all_markers_knn_results_{}.npy'), \n",
    " ('L1 VAE', 'l1_vae_results_{}.npy', 'l1_vae_knn_results_{}.npy'),\n",
    " ('Smash RF', 'smash_rf_results_{}.npy', 'smash_rf_knn_results_{}.npy'),\n",
    " ('SMaSH DNN', 'smash_results_{}.npy', 'smash_knn_results_{}.npy'),\n",
    " ('RankCorr', 'rankcorr_results_{}.npy', 'rankcorr_knn_results_{}.npy'),\n",
    " ('Global Gate VAE', 'globalgate_vae_results_{}.npy', 'globalgate_vae_knn_results_{}.npy'),\n",
    " ('MarkerMap Unsupervised', 'marker_map_unsupervised_results_{}.npy', 'marker_map_unsupervised_knn_results_{}.npy'),\n",
    " ('MarkerMap Supervised', 'marker_map_supervised_results_{}.npy', 'marker_map_supervised_knn_results_{}.npy'),\n",
    " ('MarkerMap Mixed Supervision', 'marker_map_mixed_results_{}.npy', 'marker_map_mixed_knn_results_{}.npy'),\n",
    " ('Concrete VAE',  'concrete_vae_results_{}.npy', 'concrete_vae_knn_results_{}.npy'),\n",
    " ('LassoNet', 'lasso_net_results_{}.npy', 'lasso_net_knn_results_{}.npy')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7LLoa-WyKph2"
   },
   "outputs": [],
   "source": [
    "data_proto = []\n",
    "indices = []\n",
    "for axis in result_axis: \n",
    "    data_proto.append(model_variances(model_save_path + axis[1], num_times))\n",
    "    indices.append(axis[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390
    },
    "id": "H7R_7QDnLRKV",
    "outputId": "2d01f021-49fa-4ace-a430-3c2fc646f171"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(data_proto, index = indices, \n",
    "             columns = ['Misclassification Mean', 'Weighted F1 Mean', 'Misclassification Standard Deviation', 'Weighted F1 Standard Deviation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xd6k1DKY2D1I"
   },
   "outputs": [],
   "source": [
    "data_proto = []\n",
    "indices = []\n",
    "for axis in result_axis: \n",
    "    data_proto.append(model_variances(model_save_path + axis[2], num_times))\n",
    "    indices.append(axis[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390
    },
    "id": "sYrethfX2F97",
    "outputId": "4c3bed99-cf3f-479f-8d41-ea9b09c5bd06"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(data_proto, index = indices, \n",
    "             columns = ['Misclassification Mean', 'Weighted F1 Mean', 'Misclassification Standard Deviation', 'Weighted F1 Standard Deviation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Brds9F5jRnYq"
   },
   "source": [
    "## Confusion Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RwaNGwBvxBBE"
   },
   "source": [
    "k = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ZrGsfIqfuob"
   },
   "source": [
    "### All Marker Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 469
    },
    "id": "FtEmF7DZfxox",
    "outputId": "0b18f2d3-c131-454f-8d9d-08f33926c06a"
   },
   "outputs": [],
   "source": [
    "results =  np.load(model_save_path + 'all_markers_results_{}.npy'.format(1), allow_pickle = True)\n",
    "plot_confusion_matrix(results[2], encoder.classes_, title = 'All Markers Confusion Matrix', save_path = viz_save_path + 'all_markers_cm.pdf', cmap = 'icefire')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Lp6epw4Mzxe"
   },
   "source": [
    "### Smash RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Ig5MZump1Ag"
   },
   "outputs": [],
   "source": [
    "results =  np.load(model_save_path + 'smash_rf_results_{}.npy'.format(1), allow_pickle = True)\n",
    "plot_confusion_matrix(results[2], encoder.classes_, title = 'Smash Random Forest Confusion Matrix', save_path = viz_save_path + 'smash_rf_cm.pdf', cmap = 'icefire')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oBSIPW8mhMgA"
   },
   "source": [
    "### Smash DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 469
    },
    "id": "DvUqtYkBhNdc",
    "outputId": "391ae502-0cdd-4981-96fb-6a2183dd1e14"
   },
   "outputs": [],
   "source": [
    "results =  np.load(model_save_path + 'smash_results_{}.npy'.format(1), allow_pickle = True)\n",
    "plot_confusion_matrix(results[2], encoder.classes_, title = 'Smash DNN Confusion Matrix', save_path = viz_save_path + 'smash_cm.pdf', cmap = 'icefire')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RoHIHsMhM1Jc"
   },
   "source": [
    "### RankCorr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 469
    },
    "id": "zHE1nVLnyJlY",
    "outputId": "0d34a8ae-8317-41f5-c22f-13c51040a4ad"
   },
   "outputs": [],
   "source": [
    "results =  np.load(model_save_path + 'rankcorr_results_{}.npy'.format(1), allow_pickle = True)\n",
    "plot_confusion_matrix(results[2], encoder.classes_, title = 'RankCorr Confusion Matrix', save_path = viz_save_path + 'rankcorr_cm.pdf', cmap = 'icefire')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qe0G8ulp3Cc1"
   },
   "source": [
    "### L1 VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 469
    },
    "id": "mba3I4gS3Fmb",
    "outputId": "cb5ce8bb-c4fa-40b0-b79a-56700c073b8d"
   },
   "outputs": [],
   "source": [
    "results =  np.load(model_save_path + 'l1_vae_results_{}.npy'.format(1), allow_pickle = True)\n",
    "plot_confusion_matrix(results[2], encoder.classes_, title = 'L1 VAE Confusion Matrix', save_path = viz_save_path + 'l1_vae_cm.pdf', cmap = 'icefire')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k-9W1yk1B4kK"
   },
   "source": [
    "### Global Gate VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 469
    },
    "id": "g5bZpPOvB6W6",
    "outputId": "21230f67-f431-42ad-f1d7-81e55ffd3fa4"
   },
   "outputs": [],
   "source": [
    "results =  np.load(model_save_path + 'globalgate_vae_results_{}.npy'.format(1), allow_pickle = True)\n",
    "plot_confusion_matrix(results[2], encoder.classes_, title = 'GlobalGate VAE Confusion Matrix', save_path = viz_save_path + 'globalgate_vae_cm.pdf', cmap = 'icefire')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5DqEjpEaM22D"
   },
   "source": [
    "### MarkerMap Unsupervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 469
    },
    "id": "It6Bc65UyUM2",
    "outputId": "f67f028f-617e-4d51-8ed1-f9dd47cab234"
   },
   "outputs": [],
   "source": [
    "results =  np.load(model_save_path + 'marker_map_unsupervised_results_{}.npy'.format(1), allow_pickle = True)\n",
    "plot_confusion_matrix(results[2], encoder.classes_, title = 'MarkerMap Unsupervised Confusion Matrix', save_path = viz_save_path + 'marker_map_unsupervised_cm.pdf', cmap = 'icefire')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "flI6ggosM-f8"
   },
   "source": [
    "### MarkerMap Supervised\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 469
    },
    "id": "DXrAepUb0F5G",
    "outputId": "da60e618-9224-418f-d342-5f1af7b910e2"
   },
   "outputs": [],
   "source": [
    "results =  np.load(model_save_path + 'marker_map_supervised_results_{}.npy'.format(1), allow_pickle = True)\n",
    "plot_confusion_matrix(results[2], encoder.classes_, title = 'MarkerMap Supervised Confusion Matrix', save_path = viz_save_path + 'marker_map_supervised_cm.pdf', cmap = 'icefire')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5hZzC3_FmnFE"
   },
   "source": [
    "## MarkerMap Mixed Supervision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 469
    },
    "id": "86jfWjd1mpBs",
    "outputId": "7733c47f-00b3-4350-a1ba-e329750c543e"
   },
   "outputs": [],
   "source": [
    "results =  np.load(model_save_path + 'marker_map_mixed_results_{}.npy'.format(1), allow_pickle = True)\n",
    "plot_confusion_matrix(results[2], encoder.classes_, title = 'MarkerMap Mixed Supervision Confusion Matrix', save_path = viz_save_path + 'marker_map_mixed_cm.pdf', cmap = 'icefire')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yMJD3N0JM80q"
   },
   "source": [
    "### Concrete VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 469
    },
    "id": "ET_uNpJp0Ujo",
    "outputId": "e689d7b8-853e-4b10-f7e8-3df015763098"
   },
   "outputs": [],
   "source": [
    "results =  np.load(model_save_path + 'concrete_vae_results_{}.npy'.format(1), allow_pickle = True)\n",
    "plot_confusion_matrix(results[2], encoder.classes_, title = 'Concrete VAE Confusion Matrix', save_path = viz_save_path + 'concrete_vae_cm.pdf', cmap = 'icefire')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a-c_GOqBIXYR"
   },
   "source": [
    "## LassoNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 469
    },
    "id": "fWQifcSKIab6",
    "outputId": "223c5746-e3c3-431d-a78a-f3b07ce63ed9"
   },
   "outputs": [],
   "source": [
    "results =  np.load(model_save_path + 'lasso_net_results_{}.npy'.format(1), allow_pickle = True)\n",
    "plot_confusion_matrix(results[2], encoder.classes_, title = 'LassoNet Confusion Matrix', save_path = viz_save_path + 'lasso_net_cm.pdf', cmap = 'icefire')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Zeisel.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
