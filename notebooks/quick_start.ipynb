{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed485152",
   "metadata": {},
   "source": [
    "### Imports\n",
    "Data is handled with numpy and with scanpy which is used for many computational biology datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3a5ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scanpy as sc\n",
    "\n",
    "from markermap.vae_models import MarkerMap, train_model\n",
    "from markermap.utils import (\n",
    "    new_model_metrics,\n",
    "    plot_confusion_matrix,\n",
    "    split_data,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5385390f",
   "metadata": {},
   "source": [
    "### Set Parameters\n",
    "Define some parameters that we will use when creating the MarkerMap. \n",
    "* z_size is the dimension of the latent space in the variational auto-encoder. We always use 16\n",
    "* hidden_layer_size is the dimension of the hidden layers in the auto-encoder that come before and after the latent space layer. This is dependent on the data, a good rule of thumb is ~10% of the dimension of the input data. For the CITE-seq data which has 500 columns, we will use 64\n",
    "* k is the number of markers to extract\n",
    "* batch_size is the batch size used by the model\n",
    "* Set the file_path to wherever your data is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd8eb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_size = 16\n",
    "hidden_layer_size = 64\n",
    "k=50\n",
    "batch_size=64\n",
    "\n",
    "file_path = 'data/cite_seq/CITEseq.h5ad'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff56390",
   "metadata": {},
   "source": [
    "### Data\n",
    "Set file_path to wherever your data is located. We then read in the data using scanpy which \n",
    "returns an AnnData object. The gene data is stored in adata.X, and the cell labels are stored in adata.obs['names']. For consistency across different datasets, we store the labels in the adata.obs['annotation'], but this can be controlled by the `group_by` variable.\n",
    "\n",
    "We then split the data into training, validation, and test sets with a 70%, 10%, 20% split. We can use MarkerMap.prepareData to construct the train_dataloader and val_dataloader that will be used during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435db789",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get data\n",
    "group_by = 'annotation'\n",
    "adata = sc.read_h5ad(file_path)\n",
    "adata.obs[group_by] = adata.obs['names']\n",
    "\n",
    "# we will use 70% training data, 10% vaidation data during the training of the marker map, then 20% for testing\n",
    "train_indices, val_indices, test_indices = split_data(\n",
    "    adata.X,\n",
    "    adata.obs[group_by],\n",
    "    [0.7, 0.1, 0.2],\n",
    ")\n",
    "train_val_indices = np.concatenate([train_indices, val_indices])\n",
    "\n",
    "train_dataloader, val_dataloader = MarkerMap.prepareData(\n",
    "    adata,\n",
    "    train_indices,\n",
    "    val_indices,\n",
    "    group_by,\n",
    "    None, #layer, just use adata.X\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee9ecb2",
   "metadata": {},
   "source": [
    "### Define and Train the Model\n",
    "Now it is time to define the MarkerMap. There are many hyperparameters than can be tuned here, but the most important are k and the loss_tradeoff. The k parameter may require some domain knowledge, but it is fairly easy to benchmark for different levels of k, as we will see in the later examples. Loss_tradeoff is also important, see the paper for a further discussion. In general, we have 3 levels, 0 (supervised only), 0.5 (mixed supervised-unsupervised) and 1 (unsupervised only). This step may take a couple of minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432338fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "supervised_marker_map = MarkerMap(\n",
    "    adata.X.shape[1],\n",
    "    hidden_layer_size,\n",
    "    z_size,\n",
    "    len(adata.obs[group_by].unique()),\n",
    "    k,\n",
    "    loss_tradeoff=0,\n",
    ")\n",
    "train_model(supervised_marker_map, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643d2432",
   "metadata": {},
   "source": [
    "### Evaluate the model\n",
    "Finally, we test the model. The new_model_metrics function trains a simple model such as a RandomForestClassifer on the training data restricted to the k markers, and then evaluates it on the testing data. We then print the misclassification rate, the f1-score, and plot a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519d2ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "misclass_rate, test_rep, cm = new_model_metrics(\n",
    "    adata[train_val_indices, :].X,\n",
    "    adata[train_val_indices, :].obs[group_by],\n",
    "    adata[test_indices, :].X,\n",
    "    adata[test_indices, :].obs[group_by],\n",
    "    markers = supervised_marker_map.markers().clone().cpu().detach().numpy(),\n",
    ")\n",
    "\n",
    "print(misclass_rate)\n",
    "print(test_rep['weighted avg']['f1-score'])\n",
    "plot_confusion_matrix(cm, adata.obs[group_by].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d8a3a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
